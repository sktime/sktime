{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cubic-guest",
   "metadata": {},
   "source": [
    "# Probabilistic Forecasting with `sktime`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34317b3c",
   "metadata": {},
   "source": [
    "originally presented at [pydata Berlin 2022, see there for video presentation](https://github.com/sktime/sktime-tutorial-pydata-berlin-2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf7ad11",
   "metadata": {},
   "source": [
    "### Overview of this notebook\n",
    "\n",
    "* quick start - probabilistic forecasting\n",
    "* disambiguation - types of probabilistic forecasts\n",
    "* details: probabilistic forecasting interfaces\n",
    "* metrics for, and evaluation of probabilistic forecasts\n",
    "* advanced composition: pipelines, tuning, reduction\n",
    "* extender guide\n",
    "* contributor credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c8ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6586a019",
   "metadata": {},
   "source": [
    "---\n",
    "### Quick Start - Probabilistic Forecasting with `sktime`\n",
    "\n",
    "... works exactly like the basic forecasting workflow, replace `predict` by a probabilistic method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.arima import ARIMA\n",
    "\n",
    "# step 1: data specification\n",
    "y = load_airline()\n",
    "# step 2: specifying forecasting horizon\n",
    "fh = [1, 2, 3]\n",
    "# step 3: specifying the forecasting algorithm\n",
    "forecaster = ARIMA()\n",
    "# step 4: fitting the forecaster\n",
    "forecaster.fit(y, fh=[1, 2, 3])\n",
    "# step 5: querying predictions\n",
    "y_pred = forecaster.predict()\n",
    "\n",
    "# for probabilistic forecasting:\n",
    "#   call a probabilistic forecasting method after or instead of step 5\n",
    "y_pred_int = forecaster.predict_interval(coverage=0.9)\n",
    "y_pred_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a864b9c1",
   "metadata": {},
   "source": [
    "**probabilistic forecasting methods in `sktime`**:\n",
    "\n",
    "* forecast intervals    - `predict_interval(fh=None, X=None, coverage=0.90)`\n",
    "* forecast quantiles    - `predict_quantiles(fh=None, X=None, alpha=[0.05, 0.95])`\n",
    "* forecast variance     - `predict_var(fh=None, X=None, cov=False)`\n",
    "* distribution forecast - `predict_proba(fh=None, X=None, marginal=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57a3be0",
   "metadata": {},
   "source": [
    "To check which forecasters in `sktime` support probabilistic forecasting, use the `registry.all_estimators` utility and search for estimators which have the `capability:pred_int` tag (value `True`).\n",
    "\n",
    "For composites such as pipelines, a positive tag means that logic is implemented if (some or all) components support it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7490769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\n",
    "    \"forecaster\", filter_tags={\"capability:pred_int\": True}, as_dataframe=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-deviation",
   "metadata": {},
   "source": [
    "---\n",
    "### What is probabilistic forecasting?\n",
    "\n",
    "#### Intuition\n",
    "\n",
    "* produce low/high scenarios of forecasts\n",
    "* quantify uncertainty around forecasts\n",
    "* produce expected range of variation of forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435f59bf",
   "metadata": {},
   "source": [
    "#### Interface view\n",
    "\n",
    "**Want** to produce \"distribution\" or \"range\" of forecast values,\n",
    "\n",
    "at time stamps defined by **forecasting horizon** `fh`\n",
    "\n",
    "given **past data** `y` (series), and possibly exogeneous data `X`\n",
    "\n",
    "Input, to `fit` or `predict`: `fh`, `y`, `X`\n",
    "\n",
    "Output, from `predict_probabilistic`: some \"distribution\" or \"range\" object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daec146",
   "metadata": {},
   "source": [
    "**Big caveat**: there are multiple possible ways to model \"distribution\" or \"range\"!\n",
    "\n",
    "Used in practice and easily confused! (and often, practically, confused!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c0f1dc",
   "metadata": {},
   "source": [
    "#### Formal view (endogeneous, one forecast time stamp)\n",
    "\n",
    "Let  $y(t_1), \\dots, y(t_n)$ be observations at fixed time stamps $t_1, \\dots, t_n$. \n",
    "\n",
    "(we consider $y$ as an $\\mathbb{R}^n$-valued random variable)\n",
    "\n",
    "Let $y'$ be a (true) value, which will be observed at a future time stamp $\\tau$.\n",
    "\n",
    "(we consider $y'$ as an $\\mathbb{R}$-valued random variable)\n",
    "\n",
    "We have the following \"types of forecasts\" of $y'$:\n",
    "\n",
    "| Name | param | prediction/estimate of | `sktime` |\n",
    "| ---- | ----- | ---------------------- | -------- |\n",
    "| point forecast | | conditional expectation $\\mathbb{E}[y'\\|y]$ | `predict` |\n",
    "| variance forecast | | conditional variance $Var[y'\\|y]$ | `predict_var` |\n",
    "| quantile forecast | $\\alpha\\in (0,1)$ | $\\alpha$-quantile of $y'\\|y$ | `predict_quantiles` |\n",
    "| interval forecast | $c\\in (0,1)$| $[a,b]$ s.t. $P(a\\le y' \\le b\\| y) = c$ | `predict_interval` |\n",
    "| distribution forecast | | the law/distribution of $y'\\|y$ | `predict_proba` |\n",
    "\n",
    "Notes:\n",
    "\n",
    "* different forecasters have different capabilities!\n",
    "* metrics, evaluation & tuning are different by \"type of forecast\"\n",
    "* compositors can \"add\" type of forecast! Example: bootstrap\n",
    "\n",
    "##### More formal details & intuition:\n",
    "\n",
    "* a **\"point forecast\"** is a prediction/estimate of the conditional expectation $\\mathbb{E}[y'|y]$.\\\n",
    " **Intuition**: \"out of many repetitions/worlds, this value is the arithmetic average of all observations\".\n",
    "* a **\"variance forecast\"** is a prediction/estimate of the conditional expectation $Var[y'|y]$.\\\n",
    " **Intuition:** \"out of many repetitions/worlds, this value is the average squared distance of the observation to the perfect point forecast\".\n",
    "* a **\"quantile forecast\"**, at quantile point $\\alpha\\in (0,1)$ is a prediction/estimate of the $\\alpha$-quantile of $y'|y$, i.e., of $F^{-1}_{y'|y}(\\alpha)$, where $F^{-1}$ is the (generalized) inverse cdf = quantile function of the random variable y'|y.\\\n",
    " **Intuition**: \"out of many repetitions/worlds, a fraction of exactly $\\alpha$ will have equal or smaller than this value.\"\n",
    "* an **\"interval forecast\"** or \"predictive interval\" with (symmetric) coverage $c\\in (0,1)$ is a prediction/estimate pair of lower bound $a$ and upper bound $b$ such that $P(a\\le y' \\le b| y) = c$ and $P(y' \\gneq b| y) = P(y' \\lneq a| y) = (1 - c) /2$.\\\n",
    " **Intuition**: \"out of many repetitions/worlds, a fraction of exactly $c$ will be contained in the interval $[a,b]$, and being above is equally likely as being below\".\n",
    "* a **\"distribution forecast\"** or \"full probabilistic forecast\" is a prediction/estimate of the distribution of $y'|y$, e.g., \"it's a normal distribution with mean 42 and variance 1\".\\\n",
    "**Intuition**: exhaustive description of the generating mechanism of many repetitions/worlds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425bccbe",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* lower/upper of interval forecasts are quantile forecasts at quantile points $0.5 - c/2$ and $0.5 + c/2$ (as long as forecast distributions are absolutely continuous).\n",
    "* all other forecasts can be obtained from a full probabilistic forecasts; a full probabilistic forecast can be obtained from all quantile forecasts or all interval forecasts.\n",
    "* there is no exact relation between the other types of forecasts (point or variance vs quantile)\n",
    "* in particular, point forecast does not need to be median forecast aka 0.5-quantile forecast. Can be $\\alpha$-quantile for any $\\alpha$!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5b10b6",
   "metadata": {},
   "source": [
    "Frequent confusion in literature & python packages:\n",
    "* coverage `c` vs quantile `\\alpha`\n",
    "* coverage `c` vs significance `p = 1-c`\n",
    "* quantile of lower interval bound, `p/2`, vs `p`\n",
    "* interval forecasts vs related, but substantially different concepts: confidence interval on predictive mean; Bayesian posterior or credibility interval of the predictive mean\n",
    "* all forecasts above can be Bayesian, confusion: \"posteriors are different\" or \"have to be evaluted differently\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d944c96",
   "metadata": {},
   "source": [
    "---\n",
    "### Probabilistic forecasting interfaces in `sktime` \n",
    "\n",
    "This section:\n",
    "\n",
    "* walkthrough of probabilistic predict methods\n",
    "* use in update/predict workflow\n",
    "* multivariate and hierarchical data\n",
    "\n",
    "All forecasters with tag `capability:pred_int` provide the following:\n",
    "\n",
    "* forecast intervals    - `predict_interval(fh=None, X=None, coverage=0.90)`\n",
    "* forecast quantiles    - `predict_quantiles(fh=None, X=None, alpha=[0.05, 0.95])`\n",
    "* forecast variance     - `predict_var(fh=None, X=None, cov=False)`\n",
    "* distribution forecast - `predict_proba(fh=None, X=None, marginal=True)`\n",
    "\n",
    "Generalities:\n",
    "\n",
    "* methods do not change state, multiple can be called\n",
    "* `fh` is optional, if passed late\n",
    "* exogeneous data `X` can be passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f32fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.theta import ThetaForecaster\n",
    "\n",
    "# until fit, identical with the simple workflow\n",
    "y = load_airline()\n",
    "\n",
    "fh = np.arange(1, 13)\n",
    "\n",
    "forecaster = ThetaForecaster(sp=12)\n",
    "forecaster.fit(y, fh=fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ff10e6",
   "metadata": {},
   "source": [
    "##### `predict_interval` - interval predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4995fbc2",
   "metadata": {},
   "source": [
    "Inputs:\\\n",
    "`fh` - forecasting horizon (not necessary if seen in `fit`)\\\n",
    "`coverage`, float or list of floats, default=`0.9`\\\n",
    "nominal coverage(s) of the prediction interval(s) queried\n",
    "\n",
    "Output: `pandas.DataFrame`\\\n",
    "Row index is `fh`\\\n",
    "Column has multi-index:\\\n",
    "1st level = variable name from y in fit\\\n",
    "2nd level = coverage fractions in `coverage`\\\n",
    "3rd level = string \"lower\" or \"upper\"\\\n",
    "\n",
    "Entries = forecasts of lower/upper interval at nominal coverage in 2nd lvl, for var in 1st lvl, for time in row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81bcc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = 0.9\n",
    "y_pred_ints = forecaster.predict_interval(coverage=coverage)\n",
    "y_pred_ints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9f840e",
   "metadata": {},
   "source": [
    "pretty-plotting the predictive interval forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa4f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.utils import plotting\n",
    "\n",
    "# also requires predictions\n",
    "y_pred = forecaster.predict()\n",
    "\n",
    "fig, ax = plotting.plot_series(y, y_pred, labels=[\"y\", \"y_pred\"])\n",
    "ax.fill_between(\n",
    "    ax.get_lines()[-1].get_xdata(),\n",
    "    y_pred_ints[\"Coverage\"][coverage][\"lower\"],\n",
    "    y_pred_ints[\"Coverage\"][coverage][\"upper\"],\n",
    "    alpha=0.2,\n",
    "    color=ax.get_lines()[-1].get_c(),\n",
    "    label=f\"{coverage} cov.pred.intervals\",\n",
    ")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afcdc20",
   "metadata": {},
   "source": [
    "multiple coverages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534f4490",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = [0.5, 0.9, 0.95]\n",
    "y_pred_ints = forecaster.predict_interval(coverage=coverage)\n",
    "y_pred_ints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00f1db2",
   "metadata": {},
   "source": [
    "##### `predict_quantiles` - quantile forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9468c5f4",
   "metadata": {},
   "source": [
    "Inputs:\\\n",
    "`fh` - forecasting horizon (not necessary if seen in `fit`)\\\n",
    "`alpha`, float or list of floats, default = `[0.1, 0.9]`\\\n",
    "quantile points at which quantiles are queried\n",
    "\n",
    "Output: `pandas.DataFrame`\\\n",
    "Row index is `fh`\\\n",
    "Column has multi-index:\\\n",
    "1st level = variable name from y in fit\\\n",
    "2nd level = quantile points in `alpha`\\\n",
    "\n",
    "Entries = forecasts of quantiles at quantile point in 2nd lvl, for var in 1st lvl, for time in row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76770945",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "y_pred_quantiles = forecaster.predict_quantiles(alpha=alpha)\n",
    "y_pred_quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0fb2b9",
   "metadata": {},
   "source": [
    "pretty-plotting the quantile interval forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f9cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.utils import plotting\n",
    "\n",
    "_, columns = zip(*y_pred_quantiles.iteritems())\n",
    "fig, ax = plotting.plot_series(y[-50:], *columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0002de5",
   "metadata": {},
   "source": [
    "##### `predict_var` - variance forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8566c184",
   "metadata": {},
   "source": [
    "Inputs:\\\n",
    "`fh` - forecasting horizon (not necessary if seen in `fit`)\\\n",
    "`cov`, boolean, default=False\\\n",
    "whether covariance forecasts should also be returned (not all estimators support this)\n",
    "\n",
    "Output: `pandas.DataFrame`, for cov=False:\\\n",
    "Row index is `fh`\\\n",
    "Column is equal to column index of `y` (variables)\n",
    "\n",
    "Entries = variance forecast for variable in col, for time in row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e997945",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_variance = forecaster.predict_var()\n",
    "y_pred_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df8ea93",
   "metadata": {},
   "source": [
    "with covariance, using a forecaster which can return covariance forecasts:\n",
    "\n",
    "return is `pandas.DataFrame` with `fh` indexing rows and columns;\\\n",
    "entries are forecast covariance between row and column time\\\n",
    "(diagonal = forecast variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de1e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.naive import NaiveVariance\n",
    "\n",
    "forecaster_with_covariance = NaiveVariance(forecaster)\n",
    "forecaster_with_covariance.fit(y=y, fh=fh)\n",
    "forecaster_with_covariance.predict_var(cov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25d8a7d",
   "metadata": {},
   "source": [
    "##### `predict_proba` - distribution forecasts aka \"full\" probabilistic forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16542db7",
   "metadata": {},
   "source": [
    "Inputs:\\\n",
    "`fh` - forecasting horizon (not necessary if seen in `fit`)\\\n",
    "`marginal`, bool, optional, default=True\\\n",
    "whether returned distribution is marginal over time points (True), or joint over time points (False)\\\n",
    "(not all forecasters support `marginal=False`)\n",
    "\n",
    "Output: `tensorflow-probability` `Distribution` object (requires `tensorflow` installed)\\\n",
    "if `marginal=True`: batch shape 1D, `len(fh)` (time); event shape 1D, `len(y.columns)` (variables)\\\n",
    "if `marginal=False`: event shape 2D, `[len(fh), len(y.columns)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d2e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dist = forecaster.predict_proba()\n",
    "y_pred_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b86880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining quantiles\n",
    "y_pred_dist.quantile([0.1, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining distribution parameters\n",
    "\n",
    "y_pred_dist.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87acb079",
   "metadata": {},
   "source": [
    "##### a note on consistence of methods\n",
    "\n",
    "Outputs of `predict_interval`, `predict_quantiles`, `predict_var`, `predict_proba` are *typically* but not *necessarily* consistent with each other!\n",
    "\n",
    "Consistency is weak interface requirement but not strictly enforced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd5fd21",
   "metadata": {},
   "source": [
    "#### Using probabilistic forecasts with update/predict stream workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32f8732",
   "metadata": {},
   "source": [
    "Example:\n",
    "* data observed monthly\n",
    "* make probabilistic forecasts for an entire year ahead\n",
    "* update forecasts every month\n",
    "* start in Dec 1950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1949 and 1950\n",
    "y_start = y[:24]\n",
    "# Jan 1951 etc\n",
    "y_update_batch_1 = y.loc[[\"1951-01\"]]\n",
    "y_update_batch_2 = y.loc[[\"1951-02\"]]\n",
    "y_update_batch_3 = y.loc[[\"1951-03\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dad2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now = Dec 1950\n",
    "\n",
    "# 1a. fit to data available in Dec 1950\n",
    "#   fh = [1, 2, ..., 12] for all 12 months ahead\n",
    "forecaster.fit(y_start, fh=1 + np.arange(12))\n",
    "\n",
    "# 1b. predict 1951, in Dec 1950\n",
    "forecaster.predict_interval()\n",
    "# or other proba predict functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c5c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time passes, now = Jan 1951\n",
    "\n",
    "# 2a. update forecaster with new data\n",
    "forecaster.update(y_update_batch_1)\n",
    "\n",
    "# 2b. make new prediction - year ahead = Feb 1951 to Jan 1952\n",
    "forecaster.predict_interval()\n",
    "# forecaster remembers relative forecasting horizon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f81c58",
   "metadata": {},
   "source": [
    "repeat the same commands with further data batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2736566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time passes, now = Feb 1951\n",
    "\n",
    "# 3a. update forecaster with new data\n",
    "forecaster.update(y_update_batch_2)\n",
    "\n",
    "# 3b. make new prediction - year ahead = Feb 1951 to Jan 1952\n",
    "forecaster.predict_interval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483c84c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time passes, now = Feb 1951\n",
    "\n",
    "# 4a. update forecaster with new data\n",
    "forecaster.update(y_update_batch_3)\n",
    "\n",
    "# 4b. make new prediction - year ahead = Feb 1951 to Jan 1952\n",
    "forecaster.predict_interval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcf39af",
   "metadata": {},
   "source": [
    "... and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2ddebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_selection import ExpandingWindowSplitter\n",
    "from sktime.utils.plotting import plot_windows\n",
    "\n",
    "cv = ExpandingWindowSplitter(step_length=1, fh=fh, initial_window=24)\n",
    "plot_windows(cv, y.iloc[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf857cd",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da797a68",
   "metadata": {},
   "source": [
    "#### Probabilistic forecasting for multivariate and hierarchical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2ce785",
   "metadata": {},
   "source": [
    "multivariate data: first column index for different variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d2e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_longley\n",
    "from sktime.forecasting.var import VAR\n",
    "\n",
    "_, y = load_longley()\n",
    "\n",
    "mv_forecaster = VAR()\n",
    "\n",
    "mv_forecaster.fit(y, fh=[1, 2, 3])\n",
    "# mv_forecaster.predict_var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd466ddc",
   "metadata": {},
   "source": [
    "hierarchical data: probabilistic forecasts per level are row-concatenated with a row hierarchy index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ee090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.arima import ARIMA\n",
    "from sktime.utils._testing.hierarchical import _make_hierarchical\n",
    "\n",
    "y_hier = _make_hierarchical()\n",
    "y_hier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49a126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ARIMA()\n",
    "forecaster.fit(y_hier, fh=[1, 2, 3])\n",
    "forecaster.predict_interval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74763c48",
   "metadata": {},
   "source": [
    "(more about this in the hierarchical forecasting notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-legend",
   "metadata": {},
   "source": [
    "---\n",
    "### Metrics for probabilistic forecasts and evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8cb021",
   "metadata": {},
   "source": [
    "#### overview - theory\n",
    "\n",
    "Predicted `y` has different form from true `y`, so metrics have form\n",
    "\n",
    "`metric(y_true: series, y_pred: proba_prediction) -> float`\n",
    "\n",
    "where `proba_prediction` is the type of the specific \"probabilistic prediction type\".\n",
    "\n",
    "I.e., we have the following function signature for a loss/metric $L$:\n",
    "\n",
    "| Name | param | prediction/estimate of | general form |\n",
    "| ---- | ----- | ---------------------- | -------- |\n",
    "| point forecast | | conditional expectation $\\mathbb{E}[y'\\|y]$ | `metric(y_true, y_pred)` |\n",
    "| variance forecast | | conditional variance $Var[y'\\|y]$ | `metric(y_pred, y_pt, y_var)` (requires point forecast too) |\n",
    "| quantile forecast | $\\alpha\\in (0,1)$ | $\\alpha$-quantile of $y'\\|y$ | `metric(y_true, y_quantiles, alpha)` |\n",
    "| interval forecast | $c\\in (0,1)$| $[a,b]$ s.t. $P(a\\le y' \\le b\\| y) = c$ | `metric(y_true, y_interval, c)` |\n",
    "| distribution forecast | | the law/distribution of $y'\\|y$ | `metric(y_true, y_distribution)` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c20bd6e",
   "metadata": {},
   "source": [
    "#### metrics: general signature and averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31435c23",
   "metadata": {},
   "source": [
    "intro using the example of the quantile loss aka interval loss aka pinball loss, in the univariate case.\n",
    "\n",
    "For one quantile value $\\alpha$, the (per-sample) pinball loss function is defined as\\\n",
    "$L_{\\alpha}(\\widehat{y}, y) := \\alpha \\cdot \\Theta (y - \\widehat{y}) + (1-\\alpha) \\cdot \\Theta (\\widehat{y} - y)$,\\\n",
    "where $\\Theta (x) := [1$ if $x\\ge 0$ and $0$ otherwise $]$ is the Heaviside function.\n",
    "\n",
    "This can be used to evaluate:\n",
    "\n",
    "* *multiple quantile* forecasts $\\widehat{\\bf y}:=\\widehat{y}_1, \\dots, \\widehat{y}_k$ for quantiles $\\bm{\\alpha} = \\alpha_1,\\dots, \\alpha_k$ via\\\n",
    "$L_{\\bm{\\alpha}}(\\widehat{\\bf y}, y) := \\frac{1}{k}\\sum_{i=1}^k L_{\\alpha_i}(\\widehat{y}_i, y)$\n",
    "* *interval forecasts* $[\\widehat{a}, \\widehat{b}]$ at symmetric coverage $c$ via\\\n",
    "$L_c([\\widehat{a},\\widehat{b}], y) := \\frac{1}{2} L_{\\alpha_{low}}(\\widehat{a}, y) + \\frac{1}{2}L_{\\alpha_{high}}(\\widehat{b}, y)$ where $\\alpha_{low} = \\frac{1-c}{2}, \\alpha_{high} = \\frac{1+c}{2}$\n",
    "\n",
    "(all are known to be strictly proper losses for their respective prediction object)\n",
    "\n",
    "There are *three things we can choose to average over*:\n",
    "\n",
    "* quantile values, if multiple are predicted - elements of `alpha` in `predict_interval(fh, alpha)`\n",
    "* time stamps in the forecasting horizon `fh` - elements of `fh` in `fit(fh)` resp `predict_interval(fh, alpha)`\n",
    "* variables in `y`, in case of multivariate (later, first we look at univariate)\n",
    "\n",
    "We will show quantile values and time stamps first:\n",
    "\n",
    "1. averaging by `fh` time stamps only -> one number per quantile value in `alpha`\n",
    "\n",
    "2. averaging over nothing -> one number per quantile value in `alpha` and `fh` time stamp\n",
    "\n",
    "3. averaging over both `fh` and quantile values in `alpha` -> one number\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c020c0",
   "metadata": {},
   "source": [
    "first, generating some quantile predictions.\n",
    "`pred_quantiles` now contains quantile forecasts\\\n",
    "formally, forecasts $\\widehat{y}_j(t_i)$ where $\\widehat{y_j}$ are forecasts at quantile $\\alpha_j$, with range $i=1\\dots N, j=1\\dots k$\\\n",
    "$\\alpha_j$ are the elements of `alpha`, and $t_i$ are the future time stamps indexed by `fh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660fc4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.theta import ThetaForecaster\n",
    "\n",
    "y_train = load_airline()[0:24]  # train on 24 months, 1949 and 1950\n",
    "y_test = load_airline()[24:36]  # ground truth for 12 months in 1951\n",
    "\n",
    "# try to forecast 12 months ahead, from y_train\n",
    "fh = np.arange(1, 13)\n",
    "\n",
    "forecaster = ThetaForecaster(sp=12)\n",
    "forecaster.fit(y_train, fh=fh)\n",
    "\n",
    "pred_quantiles = forecaster.predict_quantiles(alpha=[0.1, 0.25, 0.5, 0.75, 0.9])\n",
    "pred_quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca086cc1",
   "metadata": {},
   "source": [
    "1. computing the loss by quantile point or interval end, averaged over `fh` time stamps\\\n",
    "i.e., $\\frac{1}{N} \\sum_{i=1}^N L_{\\alpha}(\\widehat{y}(t_i), y(t_i))$ for $t_i$ in the `fh`, and every `alpha`,\n",
    "this is one number per quantile value in `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting.probabilistic import PinballLoss\n",
    "\n",
    "loss = PinballLoss(score_average=False)\n",
    "loss(y_true=y_test, y_pred=pred_quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4537b68",
   "metadata": {},
   "source": [
    "2. computing the the individual loss values, by sample, no averaging,\\\n",
    "i.e., $L_{\\alpha}(\\widehat{y}(t_i), y(t_i))$ for every $t_i$ in `fh` and every $\\alpha$ in `alpha`\\\n",
    "this is one number per quantile value $\\alpha$ in `alpha` and time point $t_i$ in `fh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c033800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.evaluate_by_index(y_true=y_test, y_pred=pred_quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf5aac3",
   "metadata": {},
   "source": [
    "3. computing the loss for a multiple quantile forecast, averaged over `fh` time stamps and quantile values `alpha`\\\n",
    "i.e., $\\frac{1}{Nk} \\sum_{j=1}^k\\sum_{i=1}^N L_{\\alpha_j}(\\widehat{y_j}(t_i), y(t_i))$ for $t_i$ in `fh`, and quantile values $\\alpha_j$,\\\n",
    "this is a single number that can be used in tuning (e.g., grid search) or evaluation overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97479196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting.probabilistic import PinballLoss\n",
    "\n",
    "loss_multi = PinballLoss(score_average=True)\n",
    "loss_multi(y_true=y_test, y_pred=pred_quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759cc7f8",
   "metadata": {},
   "source": [
    "4. computing the loss for a multiple quantile forecast, averaged quantile values `alpha`, for individual time stamps\\\n",
    "i.e., $\\frac{1}{k} \\sum_{j=1}^k L_{\\alpha_j}(\\widehat{y_j}(t_i), y(t_i))$ for $t_i$ in `fh`, and quantile values $\\alpha_j$,\\\n",
    "this is a univariate time series at `fh` times $t_i$, it can be used for tuning or evaluation by horizon index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_multi.evaluate_by_index(y_true=y_test, y_pred=pred_quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c94017",
   "metadata": {},
   "source": [
    "Question: why is `score_average` a constructor flag, and `evaluate_by_index` a method?\n",
    "\n",
    "* not all losses are \"by index\", so `evaluate_by_index` logic can vary (e.g., pseudo-samples)\n",
    "* constructor args define \"mathematical object\" of scientific signature: series -> non-temporal object\\\n",
    "methods define action or \"way to apply\", e.g., as used in tuning or reporting\n",
    "\n",
    "Compare `score_average` to `multioutput` arg in `scikit-learn` metrics and `sktime`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15ecf62",
   "metadata": {},
   "source": [
    "#### metrics: interval vs quantile metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e18fcf9",
   "metadata": {},
   "source": [
    "Interval and quantile metrics can be used interchangeably:\n",
    "\n",
    "internally, these are easily convertible to each other\\\n",
    "recall: lower/upper interval = quantiles at $\\frac{1}{2} \\pm \\frac{1}2$ `coverage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d0df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_interval = forecaster.predict_interval(coverage=0.8)\n",
    "pred_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142c0af",
   "metadata": {},
   "source": [
    "loss object recognizes input type automatically and computes corresponding interval loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4857f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(y_true=y_test, y_pred=pred_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa588117",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_multi(y_true=y_test, y_pred=pred_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dac797f",
   "metadata": {},
   "source": [
    "#### evaluation by backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e0f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.model_evaluation import evaluate\n",
    "from sktime.forecasting.model_selection import ExpandingWindowSplitter\n",
    "from sktime.forecasting.theta import ThetaForecaster\n",
    "from sktime.performance_metrics.forecasting.probabilistic import PinballLoss\n",
    "\n",
    "# 1. define data\n",
    "y = load_airline()\n",
    "\n",
    "# 2. define splitting/backtesting regime\n",
    "fh = [1, 2, 3]\n",
    "cv = ExpandingWindowSplitter(step_length=12, fh=fh, initial_window=72)\n",
    "\n",
    "# 3. define loss to use\n",
    "loss = PinballLoss()\n",
    "# default is score_average=True and multi_output=\"uniform_average\", so gives a number\n",
    "\n",
    "forecaster = ThetaForecaster(sp=12)\n",
    "results = evaluate(\n",
    "    forecaster=forecaster, y=y, cv=cv, strategy=\"refit\", return_data=True, scoring=loss\n",
    ")\n",
    "results.iloc[:, :5].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b98ad3",
   "metadata": {},
   "source": [
    "* each row is one train/test split in the walkforward setting\n",
    "* first col is the loss on the test fold\n",
    "* last two columns summarize length of training window, cutoff between train/test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3ab695",
   "metadata": {},
   "source": [
    "roadmap items:\n",
    "\n",
    "implementing further metrics\n",
    "\n",
    "* distribution prediction metrics - may need tfp extension\n",
    "* advanced evaluation set-ups\n",
    "* variance loss\n",
    "\n",
    "contributions are appreciated!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-union",
   "metadata": {},
   "source": [
    "---\n",
    "### Advanced composition: pipelines, tuning, reduction, adding proba forecasts to any estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d2367c",
   "metadata": {},
   "source": [
    "composition = constructing \"composite\" estimators out of multiple \"component\" estimators\n",
    "\n",
    "* **reduction** = building estimator type A using estimator type B\n",
    "    * special case: adding proba forecasting capability to non-proba forecaster\n",
    "    * special case: using proba supervised learner for  proba forecasting\n",
    "* **pipelining** = chaining estimators, here: transformers to a forecaster\n",
    "* **tuning** = automated hyper-parameter fitting, usually via internal evaluation loop\n",
    "    * special case: grid parameter search and random parameter search tuning\n",
    "    * special case: \"Auto-ML\", optimizing not just estimator hyper-parameter but also choice of estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e72a7e",
   "metadata": {},
   "source": [
    "#### Adding probabilistic forecasts to non-probabilistic forecasters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea37cf77",
   "metadata": {},
   "source": [
    "start with a forecaster that does not produce probabilistic predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abda0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
    "\n",
    "my_forecaster = ExponentialSmoothing()\n",
    "\n",
    "# does the forecaster support probabilistic predictions?\n",
    "my_forecaster.get_tag(\"capability:pred_int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd78bfe",
   "metadata": {},
   "source": [
    "adding probabilistic predictions is possible via reduction wrappers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b0664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaiveVariance adds intervals & variance via collecting past residuals\n",
    "from sktime.forecasting.naive import NaiveVariance\n",
    "\n",
    "# create a composite forecaster like this:\n",
    "my_forecaster_with_proba = NaiveVariance(my_forecaster)\n",
    "\n",
    "# does it support probabilistic predictions now?\n",
    "my_forecaster_with_proba.get_tag(\"capability:pred_int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a47135c",
   "metadata": {},
   "source": [
    "the composite can now be used like any probabilistic forecaster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e6bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = load_airline()\n",
    "\n",
    "my_forecaster_with_proba.fit(y, fh=[1, 2, 3])\n",
    "my_forecaster_with_proba.predict_interval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e6326f",
   "metadata": {},
   "source": [
    "roadmap items:\n",
    "\n",
    "more compositors to enable probabilistic forecasting\n",
    "\n",
    "* bootstrap forecast intervals\n",
    "* reduction to probabilistic supervised learning\n",
    "* popular \"add probabilistic capability\" wrappers\n",
    "\n",
    "contributions are appreciated!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-campus",
   "metadata": {},
   "source": [
    "#### Tuning and AutoML "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e913454",
   "metadata": {},
   "source": [
    "tuning and autoML with probabilistic forecasters works exactly like with \"ordinary\" forecasters\\\n",
    "via `ForecastingGridSearchCV` or `ForecastingRandomSearchCV`\n",
    "\n",
    "* change metric to tune to a probabilistic metric\n",
    "* use a corresponding probabilistic metric or loss function\n",
    "\n",
    "Internally, evaluation will be done using probabilistic metric, via backtesting evaluation.\n",
    "\n",
    "**important**: to evaluate the tuned estimator, use it in `evaluate` or a separate benchmarking workflow.\\\n",
    "Using internal metric/loss values amounts to in-sample evaluation, which is over-optimistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_selection import (\n",
    "    ForecastingGridSearchCV,\n",
    "    SlidingWindowSplitter,\n",
    ")\n",
    "from sktime.forecasting.theta import ThetaForecaster\n",
    "from sktime.performance_metrics.forecasting.probabilistic import PinballLoss\n",
    "\n",
    "# forecaster we want to tune\n",
    "forecaster = ThetaForecaster()\n",
    "\n",
    "# parameter grid to search over\n",
    "param_grid = {\"sp\": [1, 6, 12]}\n",
    "\n",
    "# evaluation/backtesting regime for *tuning*\n",
    "fh = [1, 2, 3]  # fh for tuning regime, does not need to be same as in fit/predict!\n",
    "cv = SlidingWindowSplitter(window_length=36, fh=fh)\n",
    "scoring = PinballLoss()\n",
    "\n",
    "# construct the composite forecaster with grid search compositor\n",
    "gscv = ForecastingGridSearchCV(\n",
    "    forecaster, cv=cv, param_grid=param_grid, scoring=scoring, strategy=\"refit\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "\n",
    "y = load_airline()[:60]\n",
    "\n",
    "gscv.fit(y, fh=fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a297df",
   "metadata": {},
   "source": [
    "inspect hyper-parameter fit obtained by tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5245bb",
   "metadata": {},
   "source": [
    "obtain predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133d779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.predict_interval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a287cf6e",
   "metadata": {},
   "source": [
    "for AutoML, use the `MultiplexForecaster` to select among multiple forecasters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.compose import MultiplexForecaster\n",
    "from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
    "from sktime.forecasting.naive import NaiveForecaster, NaiveVariance\n",
    "\n",
    "forecaster = MultiplexForecaster(\n",
    "    forecasters=[\n",
    "        (\"naive\", NaiveForecaster(strategy=\"last\")),\n",
    "        (\"ets\", ExponentialSmoothing(trend=\"add\", sp=12)),\n",
    "    ],\n",
    ")\n",
    "\n",
    "forecaster_param_grid = {\"selected_forecaster\": [\"ets\", \"naive\"]}\n",
    "gscv = ForecastingGridSearchCV(forecaster, cv=cv, param_grid=forecaster_param_grid)\n",
    "\n",
    "gscv.fit(y)\n",
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-belize",
   "metadata": {},
   "source": [
    "#### Pipelines with probabilistic forecasters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd70b6a2",
   "metadata": {},
   "source": [
    "`sktime` pipelines are compatible with probabilistic forecasters:\n",
    "\n",
    "* `ForecastingPipeline` applies transformers to the exogeneous `X` argument before passing them to the forecaster\n",
    "* `TransformedTargetForecaster` transforms `y` and back-transforms forecasts, including interval or quantile forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce8b6f1",
   "metadata": {},
   "source": [
    "`ForecastingPipeline` takes a chain of transformers and forecasters, say,\n",
    "\n",
    "`[t1, t2, ..., tn, f]`,\n",
    "\n",
    "where `t[i]` are forecasters that pre-process, and `tp[i]` are forecasters that postprocess\n",
    "\n",
    "##### `fit(y, X, fh)` does:\n",
    "\n",
    "`X1 = t1.fit_transform(X)`\\\n",
    "`X2 = t2.fit_transform(X1)`\\\n",
    "etc\\\n",
    "`X[n] = t3.fit_transform(X[n-1])`\\\n",
    "\n",
    "`f.fit(y=y, x=X[n])`\n",
    "\n",
    "##### `predict_[sth](X, fh)` does:\n",
    "\n",
    "`X1 = t1.transform(X)`\\\n",
    "`X2 = t2.transform(X1)`\\\n",
    "etc\\\n",
    "`X[n] = t3.transform(X[n-1])`\n",
    "\n",
    "`f.predict_[sth](X=X[n], fh)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcab36a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_macroeconomic\n",
    "from sktime.forecasting.arima import ARIMA\n",
    "from sktime.forecasting.compose import ForecastingPipeline\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.transformations.series.impute import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610257c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_macroeconomic()\n",
    "y = data[\"unemp\"]\n",
    "X = data.drop(columns=[\"unemp\"])\n",
    "\n",
    "y_train, y_test, X_train, X_test = temporal_train_test_split(y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c04ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ForecastingPipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", Imputer(method=\"mean\")),\n",
    "        (\"forecaster\", ARIMA(suppress_warnings=True)),\n",
    "    ]\n",
    ")\n",
    "forecaster.fit(y=y_train, X=X_train, fh=X_test.index[:5])\n",
    "forecaster.predict_interval(X=X_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0081f4b9",
   "metadata": {},
   "source": [
    "`TransformedTargetForecaster` takes a chain of transformers and forecasters, say,\n",
    "\n",
    "`[t1, t2, ..., tn, f, tp1, tp2, ..., tk]`,\n",
    "\n",
    "where `t[i]` are forecasters that pre-process, and `tp[i]` are forecasters that postprocess\n",
    "\n",
    "##### `fit(y, X, fh)` does:\\\n",
    "`y1 = t1.fit_transform(y)`\\\n",
    "`y2 = t2.fit_transform(y1)`\\\n",
    "`y3 = t3.fit_transform(y2)`\\\n",
    "etc\\\n",
    "`y[n] = t3.fit_transform(y[n-1])`\n",
    "\n",
    "`f.fit(y[n])`\n",
    "\n",
    "`yp1 = tp1.fit_transform(yn)`\\\n",
    "`yp2 = tp2.fit_transform(yp1)`\\\n",
    "`yp3 = tp3.fit_transform(yp2)`\\\n",
    "etc\n",
    "\n",
    "##### `predict_quantiles(y, X, fh)` does:\n",
    "\n",
    "`y1 = t1.transform(y)`\\\n",
    "`y2 = t2.transform(y1)`\\\n",
    "etc\\\n",
    "`y[n] = t3.transform(y[n-1])`\n",
    "\n",
    "`y_pred = f.predict_quantiles(y[n])`\n",
    "\n",
    "`y_pred = t[n].inverse_transform(y_pred)`\\\n",
    "`y_pred = t[n-1].inverse_transform(y_pred)`\\\n",
    "etc\\\n",
    "`y_pred = t1.inverse_transform(y_pred)`\\\n",
    "`y_pred = tp1.transform(y_pred)`\\\n",
    "`y_pred = tp2.transform(y_pred)`\\\n",
    "etc\\\n",
    "`y_pred = tp[n].transform(y_pred)`\\\n",
    "\n",
    "**Note**: the remaining proba predictions are inferred from `predict_quantiles`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_macroeconomic\n",
    "from sktime.forecasting.arima import ARIMA\n",
    "from sktime.forecasting.compose import TransformedTargetForecaster\n",
    "from sktime.transformations.series.detrend import Deseasonalizer, Detrender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4f08da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_macroeconomic()\n",
    "y = data[[\"unemp\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = TransformedTargetForecaster(\n",
    "    [\n",
    "        (\"deseasonalize\", Deseasonalizer(sp=12)),\n",
    "        (\"detrend\", Detrender()),\n",
    "        (\"forecast\", ARIMA()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "forecaster.fit(y, fh=[1, 2, 3])\n",
    "forecaster.predict_interval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c47e57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.predict_quantiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15246bc7",
   "metadata": {},
   "source": [
    "quick creation also possible via the `*` dunder method, same pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07deb7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = Deseasonalizer(sp=12) * Detrender() * ARIMA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9e9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.fit(y, fh=[1, 2, 3])\n",
    "forecaster.predict_interval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-guarantee",
   "metadata": {},
   "source": [
    "---\n",
    "## Building your own probabilistic forecaster\n",
    "\n",
    "Getting started:\n",
    "\n",
    "* follow the [\"implementing estimator\" developer guide](https://www.sktime.org/en/stable/developer_guide/add_estimators.html)\n",
    "* use the advanced [forecasting extension template](https://github.com/sktime/sktime/blob/main/extension_templates/forecasting.py)\n",
    "\n",
    "Extension template = python \"fill-in\" template with to-do blocks that allow you to implement your own, sktime-compatible forecasting algorithm.\n",
    "\n",
    "Check estimators using `check_estimator`\n",
    "\n",
    "For probabilistic forecasting:\n",
    "\n",
    "* implement at least one of `predict_quantiles`, `predict_interval`, `predict_var`, `predict_proba`\n",
    "* optimally, implement all, unless identical with defaulting behaviour as below\n",
    "* if only one is implemented, others use following defaults (in this sequence, dependent availability):\n",
    "    * `predict_interval` uses quantiles from `predict_quantiles` and vice versa\n",
    "    * `predict_var` uses variance from `predict_proba`, or variance of normal with IQR as obtained from `predict_quantiles`\n",
    "    * `predict_interval` or `predict_quantiles` uses quantiles from `predict_proba` distribution\n",
    "    * `predict_proba` returns normal with mean `predict` and variance `predict_var`\n",
    "* so if predictive residuals not normal, implement `predict_proba` or `predict_quantiles`\n",
    "* if interfacing, implement the ones where least \"conversion\" is necessary\n",
    "* ensure to set the `capability:pred_int` tag to `True`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59af90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator checking on the fly using check_estimator\n",
    "\n",
    "# suppose this is your new estimator\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.utils.estimator_checks import check_estimator\n",
    "\n",
    "# check the estimator like this:\n",
    "check_estimator(NaiveForecaster)\n",
    "# this prints any failed tests, and returns dictionary with\n",
    "#   keys of test runs and results from the test run\n",
    "# run individual tests using the tests_to_run arg or the fixtures_to_run_arg\n",
    "#   these need to be identical to test or test/fixture names, see docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cdfc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to raise errors for use in traceback debugging:\n",
    "check_estimator(NaiveForecaster, raise_exceptions=True)\n",
    "# this does not raise an error since NaiveForecaster is fine, but would if it weren't"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-eleven",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-narrow",
   "metadata": {},
   "source": [
    "* unified API for probabilistic forecasting and probabilistic metrics\n",
    "* integrating other packages (e.g. scikit-learn, statsmodels, pmdarima, prophet)\n",
    "* interface for composite model building is same, proba or not (pipelining, ensembling, tuning, reduction)\n",
    "* easily extensible with custom estimators\n",
    "\n",
    "### Useful resources\n",
    "* For more details, take a look at [our paper on forecasting with sktime](https://arxiv.org/abs/2005.08067) in which we discuss the forecasting API in more detail and use it to replicate and extend the M4 study.\n",
    "* For a good introduction to forecasting, see [Hyndman, Rob J., and George Athanasopoulos. Forecasting: principles and practice. OTexts, 2018](https://otexts.com/fpp2/).\n",
    "* For comparative benchmarking studies/forecasting competitions, see the [M4 competition](https://www.sciencedirect.com/science/article/pii/S0169207019301128) and the [M5 competition](https://www.kaggle.com/c/m5-forecasting-accuracy/overview).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7447f2",
   "metadata": {},
   "source": [
    "### Credits\n",
    "\n",
    "notebook creation: fkiraly\n",
    "\n",
    "probablistic forecasting framework: fkiraly, kejsitake\\\n",
    "probabilistic metrics, tuning: eenticott-shell, fkiraly\\\n",
    "probabilistic estimators: aiwalter, fkiraly, ilyasmoutawwakil, k1m190r, kejsitake"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
