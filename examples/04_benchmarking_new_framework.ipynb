{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking with sktime\n",
    "\n",
    "The benchmarking modules allows you to easily orchestrate benchmarking experiments in which you want to compare the performance of one or more algorithms over one or more data sets. It also provides a number of statistical tests to check if observed performance differences are statistically significant.\n",
    "\n",
    "\n",
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T13:57:12.800774Z",
     "iopub.status.busy": "2021-04-09T13:57:12.800145Z",
     "iopub.status.idle": "2021-04-09T13:57:13.736550Z",
     "shell.execute_reply": "2021-04-09T13:57:13.736911Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benediktheidrich/code/sktime/venv/lib/python3.10/site-packages/gluonts/json.py:102: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import required functions and classes\n",
    "import warnings\n",
    "\n",
    "from sktime.benchmarking.forecasting_new import (\n",
    "    ForecastingBenchmark as ForecastingBenchmarkNew,\n",
    ")\n",
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.moirai_forecaster import MOIRAIForecaster\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.forecasting.reconcile import ReconcilerForecaster\n",
    "from sktime.forecasting.ttm import TinyTimeMixerForecaster\n",
    "from sktime.performance_metrics.forecasting import (\n",
    "    MeanAbsoluteError, MeanSquaredError\n",
    ")\n",
    "from sktime.split import SlidingWindowSplitter\n",
    "\n",
    "# hide warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Time Series Forecasting Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T13:57:13.745627Z",
     "iopub.status.busy": "2021-04-09T13:57:13.745080Z",
     "iopub.status.idle": "2021-04-09T13:57:13.747037Z",
     "shell.execute_reply": "2021-04-09T13:57:13.747533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyTimeMixerForecaster\n",
      "[ScoreResult(name='MeanAbsoluteError', score=array([60.63170647])), ScoreResult(name='fit_time', score=0.9096122640088046), ScoreResult(name='pred_time', score=0.008292305671299497), ScoreResult(name='MeanSquaredError', score=array([[  722.77371458],\n",
      "       [ 1981.52833039],\n",
      "       [  340.57998238],\n",
      "       [  292.40980806],\n",
      "       [  725.22844361],\n",
      "       [ 7601.74786264],\n",
      "       [27253.51022393],\n",
      "       [28027.72359794],\n",
      "       [ 5546.53886084],\n",
      "       [ 1621.03561193],\n",
      "       [  377.11442601]]))]\n",
      "---\n",
      "MOIRAIForecaster\n",
      "[ScoreResult(name='MeanAbsoluteError', score=array([51.64224891])), ScoreResult(name='fit_time', score=0.24815930565819144), ScoreResult(name='pred_time', score=0.036989958345657215), ScoreResult(name='MeanSquaredError', score=array([[  408.61350485],\n",
      "       [ 2965.37288656],\n",
      "       [ 1207.73995765],\n",
      "       [ 1216.85289357],\n",
      "       [  743.90950801],\n",
      "       [ 1972.86096729],\n",
      "       [15208.95814726],\n",
      "       [16816.04782807],\n",
      "       [ 1783.51137201],\n",
      "       [  644.58992166],\n",
      "       [ 4123.24457185]]))]\n",
      "---\n",
      "NaiveForecaster\n",
      "[ScoreResult(name='MeanAbsoluteError', score=array([76.96969697])), ScoreResult(name='fit_time', score=0.0019242223255181063), ScoreResult(name='pred_time', score=0.004409430335120608), ScoreResult(name='MeanSquaredError', score=array([[  229.66666667],\n",
      "       [  181.66666667],\n",
      "       [ 1877.66666667],\n",
      "       [ 2253.66666667],\n",
      "       [ 4035.66666667],\n",
      "       [14975.33333333],\n",
      "       [38545.        ],\n",
      "       [39415.33333333],\n",
      "       [10369.66666667],\n",
      "       [ 2855.        ],\n",
      "       [  508.66666667]]))]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "benchmark = ForecastingBenchmarkNew()\n",
    "\n",
    "\n",
    "## Add estimators\n",
    "benchmark.add_estimator(TinyTimeMixerForecaster())\n",
    "benchmark.add_estimator(MOIRAIForecaster(\"sktime/moirai-1.0-R-small\"))\n",
    "\n",
    "\n",
    "# TODO need rerun if new metric is added\n",
    "# TODO need to handle metrics with same name\n",
    "# TODO handle global forecasting\n",
    "# TODO Add other tasks (classification, anomaly detection, etc)\n",
    "# TODO ResultObject to dataframe method. \n",
    "\n",
    "scorers = [MeanAbsoluteError(multilevel=\"raw_values\"), MeanSquaredError(multilevel=\"raw_values\", by_index=True)]\n",
    "\n",
    "benchmark.add_task(\n",
    "    load_airline,\n",
    "    SlidingWindowSplitter(range(1, 12), 108, 12),\n",
    "    scorers,\n",
    ")\n",
    "\n",
    "benchmark_result = benchmark.run(\n",
    "    \"./benchmarking_results.json\",\n",
    ")\n",
    "for result in benchmark_result.results:\n",
    "    print(result.model_id)\n",
    "    print(result.means)\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T13:57:13.750377Z",
     "iopub.status.busy": "2021-04-09T13:57:13.749904Z",
     "iopub.status.idle": "2021-04-09T13:57:13.751552Z",
     "shell.execute_reply": "2021-04-09T13:57:13.752038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyTimeMixerForecaster\n",
      "[ScoreResult(name='MeanAbsoluteError', score=array([60.63170647])), ScoreResult(name='fit_time', score=0.9096122640088046), ScoreResult(name='pred_time', score=0.008292305671299497), ScoreResult(name='MeanSquaredError', score=array([[  722.77371458],\n",
      "       [ 1981.52833039],\n",
      "       [  340.57998238],\n",
      "       [  292.40980806],\n",
      "       [  725.22844361],\n",
      "       [ 7601.74786264],\n",
      "       [27253.51022393],\n",
      "       [28027.72359794],\n",
      "       [ 5546.53886084],\n",
      "       [ 1621.03561193],\n",
      "       [  377.11442601]]))]\n",
      "---\n",
      "MOIRAIForecaster\n",
      "[ScoreResult(name='MeanAbsoluteError', score=array([51.64224891])), ScoreResult(name='fit_time', score=0.24815930565819144), ScoreResult(name='pred_time', score=0.036989958345657215), ScoreResult(name='MeanSquaredError', score=array([[  408.61350485],\n",
      "       [ 2965.37288656],\n",
      "       [ 1207.73995765],\n",
      "       [ 1216.85289357],\n",
      "       [  743.90950801],\n",
      "       [ 1972.86096729],\n",
      "       [15208.95814726],\n",
      "       [16816.04782807],\n",
      "       [ 1783.51137201],\n",
      "       [  644.58992166],\n",
      "       [ 4123.24457185]]))]\n",
      "---\n",
      "NaiveForecaster\n",
      "[ScoreResult(name='MeanAbsoluteError', score=array([76.96969697])), ScoreResult(name='fit_time', score=0.0019242223255181063), ScoreResult(name='pred_time', score=0.004409430335120608), ScoreResult(name='MeanSquaredError', score=array([[  229.66666667],\n",
      "       [  181.66666667],\n",
      "       [ 1877.66666667],\n",
      "       [ 2253.66666667],\n",
      "       [ 4035.66666667],\n",
      "       [14975.33333333],\n",
      "       [38545.        ],\n",
      "       [39415.33333333],\n",
      "       [10369.66666667],\n",
      "       [ 2855.        ],\n",
      "       [  508.66666667]]))]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "benchmark.add_estimator(NaiveForecaster(strategy=\"last\"))\n",
    "\n",
    "benchmark_result = benchmark.run(\n",
    "    \"./benchmarking_results.json\",\n",
    ")\n",
    "\n",
    "for result in benchmark_result.results:\n",
    "    print(result.model_id)\n",
    "    print(result.means)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following cell shows that data can also be passed directly either via a tuple containing y and X or only a y object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 32\u001b[0m\n\u001b[1;32m     19\u001b[0m benchmark\u001b[38;5;241m.\u001b[39madd_task(\n\u001b[1;32m     20\u001b[0m     load_airline(),\n\u001b[1;32m     21\u001b[0m     SlidingWindowSplitter(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m12\u001b[39m), \u001b[38;5;241m108\u001b[39m, \u001b[38;5;241m12\u001b[39m),\n\u001b[1;32m     22\u001b[0m     scorers,\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     25\u001b[0m benchmark\u001b[38;5;241m.\u001b[39madd_task(\n\u001b[1;32m     26\u001b[0m     (load_airline(), load_airline()),\n\u001b[1;32m     27\u001b[0m     SlidingWindowSplitter(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m12\u001b[39m), \u001b[38;5;241m108\u001b[39m, \u001b[38;5;241m12\u001b[39m),\n\u001b[1;32m     28\u001b[0m     scorers,\n\u001b[1;32m     29\u001b[0m     task_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY=X\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 32\u001b[0m benchmark_result \u001b[38;5;241m=\u001b[39m \u001b[43mbenchmark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./benchmarking_results_additional.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m benchmark_result\u001b[38;5;241m.\u001b[39mresults:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mmodel_id)\n",
      "File \u001b[0;32m~/code/sktime/sktime/benchmarking/forecasting_new.py:229\u001b[0m, in \u001b[0;36mForecastingBenchmark.run\u001b[0;34m(self, results_path, force_rerun)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    228\u001b[0m         logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning validation - model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 229\u001b[0m         results\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    231\u001b[0m results\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/code/sktime/sktime/benchmarking/forecasting_new.py:238\u001b[0m, in \u001b[0;36mForecastingBenchmark._run_validation\u001b[0;34m(self, task, estimator)\u001b[0m\n\u001b[1;32m    236\u001b[0m scorers \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mscorers\n\u001b[1;32m    237\u001b[0m y, X \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mget_y_X()\n\u001b[0;32m--> 238\u001b[0m scores_df \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv_splitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraise\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# TODO should be configurable\u001b[39;49;00m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# TODO should be configurable\u001b[39;49;00m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# global_mode = task.global_mode, TODO\u001b[39;49;00m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#  TODO should be configurable\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m folds \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ix, row \u001b[38;5;129;01min\u001b[39;00m scores_df\u001b[38;5;241m.\u001b[39miterrows():\n",
      "File \u001b[0;32m~/code/sktime/sktime/forecasting/model_evaluation/_functions.py:647\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(forecaster, cv, y, X, strategy, scoring, return_data, error_score, backend, cv_X, backend_params, return_model)\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    646\u001b[0m         backend_in \u001b[38;5;241m=\u001b[39m backend\n\u001b[0;32m--> 647\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mparallelize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_evaluate_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43myx_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_evaluate_window_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_in\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;66;03m# final formatting of dask dataframes\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdask_lazy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m not_parallel:\n",
      "File \u001b[0;32m~/code/sktime/sktime/utils/parallel.py:72\u001b[0m, in \u001b[0;36mparallelize\u001b[0;34m(fun, iter, meta, backend, backend_params)\u001b[0m\n\u001b[1;32m     69\u001b[0m backend_name \u001b[38;5;241m=\u001b[39m backend_dict[backend]\n\u001b[1;32m     70\u001b[0m para_fun \u001b[38;5;241m=\u001b[39m para_dict[backend_name]\n\u001b[0;32m---> 72\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mpara_fun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_params\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/code/sktime/sktime/utils/parallel.py:92\u001b[0m, in \u001b[0;36m_parallelize_none\u001b[0;34m(fun, iter, meta, backend, backend_params)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parallelize_none\u001b[39m(fun, \u001b[38;5;28miter\u001b[39m, meta, backend, backend_params):\n\u001b[1;32m     91\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute loop via simple sequential list comprehension.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     ret \u001b[38;5;241m=\u001b[39m [fun(x, meta\u001b[38;5;241m=\u001b[39mmeta) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m]\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/code/sktime/sktime/utils/parallel.py:92\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parallelize_none\u001b[39m(fun, \u001b[38;5;28miter\u001b[39m, meta, backend, backend_params):\n\u001b[1;32m     91\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute loop via simple sequential list comprehension.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     ret \u001b[38;5;241m=\u001b[39m [\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m]\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/code/sktime/sktime/forecasting/model_evaluation/_functions.py:263\u001b[0m, in \u001b[0;36m_evaluate_window\u001b[0;34m(x, meta)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_pred_key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m y_preds_cache\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    262\u001b[0m     start_pred \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m--> 263\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpred_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m     pred_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start_pred\n\u001b[1;32m    265\u001b[0m     temp_result[time_key] \u001b[38;5;241m=\u001b[39m [pred_time]\n",
      "File \u001b[0;32m~/code/sktime/sktime/forecasting/base/_base.py:2487\u001b[0m, in \u001b[0;36m_BaseGlobalForecaster.predict\u001b[0;34m(self, fh, X, y)\u001b[0m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;66;03m# we call the ordinary _predict if no looping/vectorization needed\u001b[39;00m\n\u001b[1;32m   2486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_vectorized:\n\u001b[0;32m-> 2487\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_inner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2489\u001b[0m     \u001b[38;5;66;03m# otherwise we call the vectorized version of predict\u001b[39;00m\n\u001b[1;32m   2490\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m=\u001b[39my_inner, X\u001b[38;5;241m=\u001b[39mX_inner, fh\u001b[38;5;241m=\u001b[39mfh)\n",
      "File \u001b[0;32m~/code/sktime/sktime/forecasting/moirai_forecaster.py:318\u001b[0m, in \u001b[0;36mMOIRAIForecaster._predict\u001b[0;34m(self, fh, y, X)\u001b[0m\n\u001b[1;32m    315\u001b[0m     pred_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_hierarchical_to_panel(pred_df)\n\u001b[1;32m    316\u001b[0m     _is_hierarchical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m ds_test, df_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mcreate_pandas_dataset(\n\u001b[1;32m    319\u001b[0m     pred_df, target, feat_dynamic_real, future_length\n\u001b[1;32m    320\u001b[0m )\n\u001b[1;32m    322\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcreate_predictor(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m    323\u001b[0m forecasts \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mpredict(ds_test)\n",
      "File \u001b[0;32m~/code/sktime/sktime/forecasting/moirai_forecaster.py:318\u001b[0m, in \u001b[0;36mMOIRAIForecaster._predict\u001b[0;34m(self, fh, y, X)\u001b[0m\n\u001b[1;32m    315\u001b[0m     pred_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_hierarchical_to_panel(pred_df)\n\u001b[1;32m    316\u001b[0m     _is_hierarchical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m ds_test, df_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mcreate_pandas_dataset(\n\u001b[1;32m    319\u001b[0m     pred_df, target, feat_dynamic_real, future_length\n\u001b[1;32m    320\u001b[0m )\n\u001b[1;32m    322\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcreate_predictor(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m    323\u001b[0m forecasts \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mpredict(ds_test)\n",
      "File \u001b[0;32m~/code/sktime/venv/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpydev_state \u001b[38;5;241m==\u001b[39m STATE_SUSPEND:\n\u001b[0;32m--> 988\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/code/sktime/venv/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/sktime/venv/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/code/sktime/venv/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "benchmark = ForecastingBenchmarkNew()\n",
    "\n",
    "\n",
    "## Add estimators\n",
    "benchmark.add_estimator(TinyTimeMixerForecaster())\n",
    "# USING MOIRAI fails. Probably a issue with MOIRAI TODO\n",
    "benchmark.add_estimator(MOIRAIForecaster(\"sktime/moirai-1.0-R-small\"))\n",
    "benchmark.add_estimator(NaiveForecaster(strategy=\"last\"))\n",
    "\n",
    "\n",
    "# TODO need rerun if new metric is added\n",
    "# TODO need to handle metrics with same name\n",
    "# TODO handle global forecasting\n",
    "# TODO Add other tasks (classification, anomaly detection, etc)\n",
    "# TODO ResultObject to dataframe method. \n",
    "\n",
    "scorers = [MeanAbsoluteError(multilevel=\"raw_values\"), MeanSquaredError(multilevel=\"raw_values\", by_index=True)]\n",
    "\n",
    "# benchmark.add_task(\n",
    "#     load_airline(),\n",
    "#     SlidingWindowSplitter(range(1, 12), 108, 12),\n",
    "#     scorers,\n",
    "# )\n",
    "\n",
    "benchmark.add_task(\n",
    "    (load_airline(), load_airline()),\n",
    "    SlidingWindowSplitter(range(1, 12), 108, 12),\n",
    "    scorers,\n",
    "    task_id=\"Y=X\",\n",
    ")\n",
    "\n",
    "benchmark_result = benchmark.run(\n",
    "    \"./benchmarking_results_additional.json\",\n",
    ")\n",
    "for result in benchmark_result.results:\n",
    "    print(result.model_id)\n",
    "    print(result.means)\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierachical Forecastin Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T13:57:13.755084Z",
     "iopub.status.busy": "2021-04-09T13:57:13.754630Z",
     "iopub.status.idle": "2021-04-09T13:57:13.756086Z",
     "shell.execute_reply": "2021-04-09T13:57:13.756565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReconcilerForecaster\n",
      "[ScoreResult(name='MeanAbsoluteError', score=array([199.95165371, 180.90826979, 190.42977317,  10.5       ,\n",
      "         9.5       ,  10.        , 143.24260979, 129.60019271,\n",
      "       136.42126655,  46.20904392,  41.80807708,  44.00850662])), ScoreResult(name='fit_time', score=0.03578204198856838), ScoreResult(name='pred_time', score=0.019599416496930644)]\n",
      "---\n",
      "Reconciler_2\n",
      "[ScoreResult(name='MeanAbsoluteError', score=array([244.38584522, 155.51837348,  38.08419188,  12.83333333,\n",
      "         8.16666667,   2.        , 175.07465135, 111.41121915,\n",
      "        27.2829942 ,  56.47786054,  35.94048766,   8.80119768])), ScoreResult(name='fit_time', score=0.09586581200710498), ScoreResult(name='pred_time', score=0.009146374504780397)]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "benchmark = ForecastingBenchmarkNew()\n",
    "\n",
    "forecaster = NaiveForecaster(strategy=\"last\")\n",
    "reconciler_1 = ReconcilerForecaster(forecaster, method=\"mint_shrink\")\n",
    "\n",
    "forecaster = NaiveForecaster(strategy=\"drift\")\n",
    "reconciler_2 = ReconcilerForecaster(forecaster, method=\"mint_shrink\")\n",
    "\n",
    "\n",
    "benchmark.add_estimator(reconciler_1)\n",
    "benchmark.add_estimator(reconciler_2, estimator_id=\"Reconciler_2\")\n",
    "\n",
    "\n",
    "# TODO Data generation needs to be prettier\n",
    "from sktime.transformations.hierarchical.aggregate import Aggregator\n",
    "from sktime.utils._testing.hierarchical import _bottom_hier_datagen\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    agg = Aggregator()\n",
    "\n",
    "    y = _bottom_hier_datagen(\n",
    "        no_bottom_nodes=3,\n",
    "        no_levels=1,\n",
    "        random_seed=123,\n",
    "        length=9,\n",
    "    )\n",
    "\n",
    "    y = agg.fit_transform(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "scorers = [MeanAbsoluteError(multilevel=\"raw_values\"), MeanAbsoluteError(multilevel=\"raw_values\", by_index=True)]\n",
    "\n",
    "splitter = SlidingWindowSplitter(fh=[1, 2, 3], window_length=4, step_length=2)\n",
    "\n",
    "benchmark.add_task(\n",
    "    get_data,\n",
    "    splitter,\n",
    "    scorers,\n",
    ")\n",
    "\n",
    "benchmark_result = benchmark.run(\n",
    "    \"./hierachical_benchmark.json\",\n",
    ")\n",
    "\n",
    "for result in benchmark_result.results:\n",
    "    print(result.model_id)\n",
    "    print(result.means)\n",
    "    print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
