{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac41b2a2",
   "metadata": {},
   "source": [
    "## 1. Basic Usage\n",
    "\n",
    "The `TimeSeriesSimulator` can generate time series data from various distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f69943a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:55:14.896379Z",
     "iopub.status.busy": "2026-01-28T20:55:14.896275Z",
     "iopub.status.idle": "2026-01-28T20:55:17.362859Z",
     "shell.execute_reply": "2026-01-28T20:55:17.362370Z"
    }
   },
   "outputs": [],
   "source": [
    "from sktime.benchmarking import TimeSeriesSimulator\n",
    "\n",
    "# Generate a simple normal distributed time series\n",
    "sim = TimeSeriesSimulator(\n",
    "    length=100,\n",
    "    distribution=\"normal\",\n",
    "    dist_params={\"loc\": 50, \"scale\": 10},\n",
    "    random_state=42,\n",
    ")\n",
    "y = sim.simulate()\n",
    "print(f\"Generated series: mean={y.mean():.2f}, std={y.std():.2f}\")\n",
    "y.plot(title=\"Normal Distribution\", figsize=(10, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2ba9f1",
   "metadata": {},
   "source": [
    "## 2. Different Distributions\n",
    "\n",
    "The simulator supports multiple built-in distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1757815b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:55:17.364676Z",
     "iopub.status.busy": "2026-01-28T20:55:17.364501Z",
     "iopub.status.idle": "2026-01-28T20:55:17.585024Z",
     "shell.execute_reply": "2026-01-28T20:55:17.584621Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "distributions = {\n",
    "    \"poisson\": {\"lam\": 10},\n",
    "    \"exponential\": {\"scale\": 5.0},\n",
    "    \"gamma\": {\"shape\": 2.0, \"scale\": 3.0},\n",
    "    \"uniform\": {\"low\": 0, \"high\": 20},\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, (dist_name, params) in zip(axes, distributions.items()):\n",
    "    sim = TimeSeriesSimulator(\n",
    "        length=100,\n",
    "        distribution=dist_name,\n",
    "        dist_params=params,\n",
    "        random_state=42,\n",
    "    )\n",
    "    y = sim.simulate()\n",
    "    ax.plot(y)\n",
    "    ax.set_title(f\"{dist_name.title()} Distribution\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0f17a",
   "metadata": {},
   "source": [
    "## 3. Adding Trend and Seasonality\n",
    "\n",
    "You can add trend and seasonal components to make the data more realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a892843",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:55:17.587173Z",
     "iopub.status.busy": "2026-01-28T20:55:17.587084Z",
     "iopub.status.idle": "2026-01-28T20:55:17.668134Z",
     "shell.execute_reply": "2026-01-28T20:55:17.667786Z"
    }
   },
   "outputs": [],
   "source": [
    "# Time series with linear trend and weekly seasonality\n",
    "sim = TimeSeriesSimulator(\n",
    "    length=365,\n",
    "    distribution=\"normal\",\n",
    "    dist_params={\"loc\": 50, \"scale\": 5},\n",
    "    trend=\"linear\",\n",
    "    trend_params={\"slope\": 0.1, \"intercept\": 0},\n",
    "    seasonality=7,\n",
    "    seasonality_strength=10.0,\n",
    "    random_state=42,\n",
    ")\n",
    "y = sim.simulate()\n",
    "y.plot(title=\"Time Series with Trend and Weekly Seasonality\", figsize=(12, 4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c152bb1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:55:17.669517Z",
     "iopub.status.busy": "2026-01-28T20:55:17.669427Z",
     "iopub.status.idle": "2026-01-28T20:55:17.746257Z",
     "shell.execute_reply": "2026-01-28T20:55:17.745786Z"
    }
   },
   "outputs": [],
   "source": [
    "# Multiple seasonal periods (weekly + monthly)\n",
    "sim = TimeSeriesSimulator(\n",
    "    length=365,\n",
    "    distribution=\"poisson\",\n",
    "    dist_params={\"lam\": 20},\n",
    "    trend=\"linear\",\n",
    "    trend_params={\"slope\": 0.05},\n",
    "    seasonality=[7, 30],\n",
    "    seasonality_strength=[5.0, 10.0],\n",
    "    random_state=42,\n",
    ")\n",
    "y = sim.simulate()\n",
    "y.plot(title=\"Multiple Seasonalities (Weekly + Monthly)\", figsize=(12, 4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8318d110",
   "metadata": {},
   "source": [
    "## 4. Custom Distributions\n",
    "\n",
    "You can define your own distribution function for specialized use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dde7bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:55:17.747579Z",
     "iopub.status.busy": "2026-01-28T20:55:17.747470Z",
     "iopub.status.idle": "2026-01-28T20:55:17.850593Z",
     "shell.execute_reply": "2026-01-28T20:55:17.850175Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def beta_distribution(size, random_state):\n",
    "    \"\"\"Generate beta-distributed values scaled to percentage range.\"\"\"\n",
    "    return random_state.beta(2, 5, size=size) * 100\n",
    "\n",
    "\n",
    "sim = TimeSeriesSimulator(\n",
    "    length=100,\n",
    "    distribution=beta_distribution,\n",
    "    random_state=42,\n",
    ")\n",
    "y = sim.simulate()\n",
    "print(f\"Beta distribution: mean={y.mean():.2f}%, range=[{y.min():.2f}, {y.max():.2f}]\")\n",
    "y.plot(title=\"Custom Beta Distribution (Conversion Rates)\", figsize=(10, 4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d70808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:55:17.851910Z",
     "iopub.status.busy": "2026-01-28T20:55:17.851810Z",
     "iopub.status.idle": "2026-01-28T20:55:17.917057Z",
     "shell.execute_reply": "2026-01-28T20:55:17.916637Z"
    }
   },
   "outputs": [],
   "source": [
    "def bimodal_distribution(size, random_state):\n",
    "    \"\"\"Generate bimodal distribution from mixture of two normals.\"\"\"\n",
    "    n1 = size // 2\n",
    "    n2 = size - n1\n",
    "    mode1 = random_state.normal(20, 3, size=n1)\n",
    "    mode2 = random_state.normal(80, 5, size=n2)\n",
    "    mixture = np.concatenate([mode1, mode2])\n",
    "    random_state.shuffle(mixture)\n",
    "    return mixture\n",
    "\n",
    "\n",
    "sim = TimeSeriesSimulator(\n",
    "    length=200,\n",
    "    distribution=bimodal_distribution,\n",
    "    random_state=42,\n",
    ")\n",
    "y = sim.simulate()\n",
    "y.plot(title=\"Bimodal Distribution\", figsize=(10, 4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4170d24a",
   "metadata": {},
   "source": [
    "## 5. Using with ForecastingBenchmark\n",
    "\n",
    "The simulated data can be directly used with sktime's `ForecastingBenchmark`\n",
    "to evaluate how models perform on data with specific characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa19a7ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:55:17.918489Z",
     "iopub.status.busy": "2026-01-28T20:55:17.918402Z",
     "iopub.status.idle": "2026-01-28T20:55:17.960673Z",
     "shell.execute_reply": "2026-01-28T20:55:17.960298Z"
    }
   },
   "outputs": [],
   "source": [
    "from sktime.benchmarking import TimeSeriesSimulator\n",
    "from sktime.benchmarking.forecasting import ForecastingBenchmark\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.forecasting.trend import TrendForecaster\n",
    "from sktime.performance_metrics.forecasting import (\n",
    "    MeanAbsoluteError,\n",
    "    MeanAbsolutePercentageError,\n",
    ")\n",
    "from sktime.split import ExpandingWindowSplitter\n",
    "\n",
    "# Generate Poisson-distributed data (e.g., daily count data)\n",
    "sim = TimeSeriesSimulator(\n",
    "    length=200,\n",
    "    distribution=\"poisson\",\n",
    "    dist_params={\"lam\": 25},\n",
    "    trend=\"linear\",\n",
    "    trend_params={\"slope\": 0.05},\n",
    "    random_state=42,\n",
    ")\n",
    "y = sim.simulate()\n",
    "\n",
    "print(f\"Generated data: {len(y)} observations\")\n",
    "print(f\"Mean: {y.mean():.2f}, Std: {y.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695003f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:55:17.962072Z",
     "iopub.status.busy": "2026-01-28T20:55:17.961980Z",
     "iopub.status.idle": "2026-01-28T20:55:18.564273Z",
     "shell.execute_reply": "2026-01-28T20:55:18.563796Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up the benchmark\n",
    "benchmark = ForecastingBenchmark()\n",
    "\n",
    "# Add estimators to compare\n",
    "benchmark.add_estimator(NaiveForecaster(strategy=\"last\"), estimator_id=\"naive_last\")\n",
    "benchmark.add_estimator(NaiveForecaster(strategy=\"mean\"), estimator_id=\"naive_mean\")\n",
    "benchmark.add_estimator(NaiveForecaster(strategy=\"drift\"), estimator_id=\"naive_drift\")\n",
    "benchmark.add_estimator(TrendForecaster(), estimator_id=\"trend\")\n",
    "\n",
    "# Add task with simulated data\n",
    "benchmark.add_task(\n",
    "    dataset_loader=y,\n",
    "    cv_splitter=ExpandingWindowSplitter(\n",
    "        fh=[1, 2, 3], initial_window=100, step_length=10\n",
    "    ),\n",
    "    scorers=[MeanAbsoluteError(), MeanAbsolutePercentageError()],\n",
    "    task_id=\"poisson_with_trend\",\n",
    ")\n",
    "\n",
    "# Run benchmark\n",
    "results = benchmark.run()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b91f6a",
   "metadata": {},
   "source": [
    "## 6. Comparing Models Across Different Data Distributions\n",
    "\n",
    "One powerful use case is comparing how models perform on different data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96363d0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:55:18.565541Z",
     "iopub.status.busy": "2026-01-28T20:55:18.565464Z",
     "iopub.status.idle": "2026-01-28T20:55:18.740800Z",
     "shell.execute_reply": "2026-01-28T20:55:18.740297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate different types of data\n",
    "data_scenarios = {\n",
    "    \"normal\": TimeSeriesSimulator(\n",
    "        length=150,\n",
    "        distribution=\"normal\",\n",
    "        dist_params={\"loc\": 50, \"scale\": 10},\n",
    "        random_state=42,\n",
    "    ).simulate(),\n",
    "    \"poisson\": TimeSeriesSimulator(\n",
    "        length=150, distribution=\"poisson\", dist_params={\"lam\": 20}, random_state=42\n",
    "    ).simulate(),\n",
    "    \"trending\": TimeSeriesSimulator(\n",
    "        length=150,\n",
    "        distribution=\"normal\",\n",
    "        dist_params={\"loc\": 10, \"scale\": 3},\n",
    "        trend=\"linear\",\n",
    "        trend_params={\"slope\": 0.5},\n",
    "        random_state=42,\n",
    "    ).simulate(),\n",
    "    \"seasonal\": TimeSeriesSimulator(\n",
    "        length=150,\n",
    "        distribution=\"normal\",\n",
    "        dist_params={\"loc\": 50, \"scale\": 5},\n",
    "        seasonality=7,\n",
    "        seasonality_strength=15.0,\n",
    "        random_state=42,\n",
    "    ).simulate(),\n",
    "}\n",
    "\n",
    "# Visualize the different scenarios\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, (name, data) in zip(axes, data_scenarios.items()):\n",
    "    ax.plot(data)\n",
    "    ax.set_title(f\"{name.title()} Data\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362049ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:55:18.742141Z",
     "iopub.status.busy": "2026-01-28T20:55:18.742047Z",
     "iopub.status.idle": "2026-01-28T20:55:19.486658Z",
     "shell.execute_reply": "2026-01-28T20:55:19.486120Z"
    }
   },
   "outputs": [],
   "source": [
    "# Benchmark models on each scenario\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "\n",
    "for scenario_name, y_data in data_scenarios.items():\n",
    "    benchmark = ForecastingBenchmark()\n",
    "\n",
    "    benchmark.add_estimator(NaiveForecaster(strategy=\"last\"), estimator_id=\"naive_last\")\n",
    "    benchmark.add_estimator(NaiveForecaster(strategy=\"mean\"), estimator_id=\"naive_mean\")\n",
    "    benchmark.add_estimator(\n",
    "        NaiveForecaster(strategy=\"drift\"), estimator_id=\"naive_drift\"\n",
    "    )\n",
    "\n",
    "    benchmark.add_task(\n",
    "        dataset_loader=y_data,\n",
    "        cv_splitter=ExpandingWindowSplitter(\n",
    "            fh=[1, 2, 3], initial_window=80, step_length=10\n",
    "        ),\n",
    "        scorers=[MeanAbsoluteError()],\n",
    "        task_id=scenario_name,\n",
    "    )\n",
    "\n",
    "    results = benchmark.run()\n",
    "    print(f\"\\n=== {scenario_name.upper()} ===\")\n",
    "    print(results[[\"model_id\", \"MeanAbsoluteError_mean\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca383d7c",
   "metadata": {},
   "source": [
    "## 7. Real-World Use Case: Demand Spikes\n",
    "\n",
    "A common challenge in demand forecasting is handling sudden spikes - promotional events,\n",
    "viral moments, or supply chain disruptions. Different models handle these anomalies\n",
    "differently. Let's simulate demand data with random spikes and benchmark which\n",
    "forecasting approach is most robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e6fdb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:55:19.488106Z",
     "iopub.status.busy": "2026-01-28T20:55:19.488001Z",
     "iopub.status.idle": "2026-01-28T20:55:19.618202Z",
     "shell.execute_reply": "2026-01-28T20:55:19.616937Z"
    }
   },
   "outputs": [],
   "source": [
    "def demand_with_spikes(size, random_state):\n",
    "    \"\"\"Simulate demand data with random promotional spikes.\n",
    "\n",
    "    This represents real-world retail scenarios where demand is normally\n",
    "    stable but experiences sudden spikes due to promotions, viral events,\n",
    "    or external factors.\n",
    "    \"\"\"\n",
    "    # Base demand follows a gamma distribution (always positive, slightly skewed)\n",
    "    base_demand = random_state.gamma(shape=5, scale=10, size=size)\n",
    "\n",
    "    # Add random spikes (5% of days have promotional spikes)\n",
    "    spike_probability = 0.05\n",
    "    spike_mask = random_state.random(size) < spike_probability\n",
    "    spike_multiplier = random_state.uniform(2.5, 5.0, size=size)\n",
    "\n",
    "    # Apply spikes\n",
    "    demand = base_demand.copy()\n",
    "    demand[spike_mask] = base_demand[spike_mask] * spike_multiplier[spike_mask]\n",
    "\n",
    "    return demand\n",
    "\n",
    "\n",
    "# Generate demand data with spikes\n",
    "sim = TimeSeriesSimulator(\n",
    "    length=300,\n",
    "    distribution=demand_with_spikes,\n",
    "    trend=\"linear\",\n",
    "    trend_params={\"slope\": 0.02},  # Slight growth trend\n",
    "    seasonality=7,  # Weekly pattern\n",
    "    seasonality_strength=5.0,\n",
    "    random_state=42,\n",
    ")\n",
    "demand_data = sim.simulate()\n",
    "\n",
    "# Visualize the demand with spikes\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ax.plot(demand_data, label=\"Demand\", alpha=0.8)\n",
    "ax.axhline(y=demand_data.median(), color=\"r\", linestyle=\"--\", label=\"Median Demand\")\n",
    "\n",
    "# Highlight spike regions\n",
    "spike_threshold = demand_data.quantile(0.95)\n",
    "spike_indices = demand_data[demand_data > spike_threshold].index\n",
    "ax.scatter(\n",
    "    spike_indices,\n",
    "    demand_data[spike_indices],\n",
    "    color=\"red\",\n",
    "    s=50,\n",
    "    label=f\"Spikes (>{spike_threshold:.0f})\",\n",
    "    zorder=5,\n",
    ")\n",
    "\n",
    "ax.set_title(\"Simulated Demand with Random Promotional Spikes\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Units Sold\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total observations: {len(demand_data)}\")\n",
    "print(f\"Mean demand: {demand_data.mean():.1f}, Median: {demand_data.median():.1f}\")\n",
    "spike_pct = 100 * len(spike_indices) / len(demand_data)\n",
    "print(f\"Spike days (>95th percentile): {len(spike_indices)} ({spike_pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67058261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T20:55:19.621328Z",
     "iopub.status.busy": "2026-01-28T20:55:19.621043Z",
     "iopub.status.idle": "2026-01-28T20:55:20.121116Z",
     "shell.execute_reply": "2026-01-28T20:55:20.120636Z"
    }
   },
   "outputs": [],
   "source": [
    "# Benchmark different forecasting strategies on spike-prone data\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.forecasting.trend import TrendForecaster\n",
    "from sktime.performance_metrics.forecasting import (\n",
    "    MeanAbsoluteError,\n",
    "    MeanSquaredError,\n",
    ")\n",
    "\n",
    "benchmark = ForecastingBenchmark()\n",
    "\n",
    "# Add various forecasting strategies\n",
    "benchmark.add_estimator(NaiveForecaster(strategy=\"last\"), estimator_id=\"naive_last\")\n",
    "benchmark.add_estimator(NaiveForecaster(strategy=\"mean\"), estimator_id=\"naive_mean\")\n",
    "benchmark.add_estimator(NaiveForecaster(strategy=\"drift\"), estimator_id=\"naive_drift\")\n",
    "benchmark.add_estimator(TrendForecaster(), estimator_id=\"trend\")\n",
    "\n",
    "# Set up benchmark task\n",
    "benchmark.add_task(\n",
    "    dataset_loader=demand_data,\n",
    "    cv_splitter=ExpandingWindowSplitter(\n",
    "        fh=[1, 2, 3, 7],  # Forecast 1, 2, 3, and 7 days ahead\n",
    "        initial_window=150,\n",
    "        step_length=14,\n",
    "    ),\n",
    "    scorers=[MeanAbsoluteError(), MeanSquaredError()],\n",
    "    task_id=\"demand_with_spikes\",\n",
    ")\n",
    "\n",
    "# Run the benchmark\n",
    "results = benchmark.run()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BENCHMARK RESULTS: Forecasting Demand with Spikes\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nModel Performance (lower is better):\")\n",
    "print(results[[\"model_id\", \"MeanAbsoluteError_mean\", \"MeanSquaredError_mean\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f3db8d",
   "metadata": {},
   "source": [
    "### Key Insights\n",
    "\n",
    "When dealing with demand spikes:\n",
    "\n",
    "- **Naive Mean** tends to be more robust as it averages out spikes\n",
    "- **Naive Last** can overreact to recent spikes, causing large errors\n",
    "- **MSE penalizes large errors more** - useful for identifying models that struggle with spikes\n",
    "\n",
    "This type of analysis helps practitioners choose the right forecasting strategy\n",
    "for their specific data characteristics before deploying to production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cadf3f",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "The `TimeSeriesSimulator` provides:\n",
    "\n",
    "- **Multiple distributions**: normal, poisson, exponential, gamma, uniform, binomial, lognormal\n",
    "- **Custom distributions**: Define your own distribution function (e.g., demand with spikes)\n",
    "- **Trend components**: linear, quadratic, exponential, or custom\n",
    "- **Seasonality**: Single or multiple seasonal periods\n",
    "- **Noise**: Add Gaussian noise to the series\n",
    "- **Reproducibility**: Control random state for reproducible experiments\n",
    "\n",
    "This integrates seamlessly with `ForecastingBenchmark` for systematic model evaluation\n",
    "on data with known characteristics - helping practitioners choose the right model\n",
    "before deploying to production."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
