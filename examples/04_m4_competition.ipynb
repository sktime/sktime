{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c3d87d2",
   "metadata": {},
   "source": [
    "# M4 Forecasting Competition with `sktime` Catalogues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23856e2",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to reproduce the classical benchmarks from the M4 forecasting competition using `sktime`’s catalogue and benchmarking framework.\n",
    "\n",
    "Instead of manually wiring datasets, forecasters, and metrics, `sktime` provides catalogues: reusable, declarative collections of benchmarking components.\n",
    "\n",
    "For the M4 competition, each temporal granularity (hourly, daily, weekly, monthly, quarterly, yearly) is represented by its own catalogue.\n",
    "In this notebook, we show the full end-to-end workflow using one granularity. The same pattern applies to all other M4 catalogues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e9df5f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9f0600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.benchmarking.forecasting import ForecastingBenchmark\n",
    "from sktime.catalogues import M4CompetitionCatalogueMonthly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608a86f1",
   "metadata": {},
   "source": [
    "## What is an M4 catalogue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d271108",
   "metadata": {},
   "source": [
    "An M4 catalogue is a self-contained, declarative specification of a benchmark setup.\n",
    "\n",
    "Each M4 catalogue:\n",
    "\n",
    "* Binds a single M4 dataset (one temporal granularity)\n",
    "\n",
    "* Defines a shared set of classical forecasters\n",
    "\n",
    "* Defines any forecaster which accepts dataset specific parameters like `sp`\n",
    "\n",
    "* Uses Overall Weighted Average (OWA) metric\n",
    "\n",
    "* Is fully compatible with sktime’s benchmarking framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e633d6bc",
   "metadata": {},
   "source": [
    "## Creating the benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa59ee2",
   "metadata": {},
   "source": [
    "We first create a `ForecastingBenchmark` object. This object collects datasets, forecasters, metrics, and evaluation logic, and coordinates execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ceb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = ForecastingBenchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d50b698",
   "metadata": {},
   "source": [
    "## Adding the M4 monthly catalogue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8574a5fd",
   "metadata": {},
   "source": [
    "We now add the monthly M4 catalogue to the benchmark.\n",
    "\n",
    "`ForecastingBenchmark` evaluates the Cartesian product of all added components.\n",
    "By adding a single catalogue, we ensure that datasets, forecasters, and metrics remain correctly aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark.add(M4CompetitionCatalogueMonthly())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d89d7",
   "metadata": {},
   "source": [
    "## Running the benchmark\n",
    "\n",
    "Once the catalogue is added, the benchmark can be executed end-to-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666eaed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = benchmark.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a95352",
   "metadata": {},
   "source": [
    "The resulting object contains the evaluated forecasters in a standardized, analysis-ready format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1969aa5f",
   "metadata": {},
   "source": [
    "## Extending the benchmark with a new forecaster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2253d6e",
   "metadata": {},
   "source": [
    "Catalogues define baseline benchmark configurations, but you can extend an existing benchmark by adding new forecasters on top of a catalogue-defined setup.\n",
    "\n",
    "This is useful when you want to compare your method against the classical M4 baselines while keeping datasets, metrics, and evaluation protocol unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f0b6c6",
   "metadata": {},
   "source": [
    "### Adding a custom forecaster\n",
    "\n",
    "Below, we add a new forecaster to the benchmark after the M4 monthly catalogue has been registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.moirai_forecaster import MOIRAIForecaster\n",
    "\n",
    "morai_forecaster = MOIRAIForecaster(checkpoint_path=\"sktime/moirai-1.0-R-small\")\n",
    "benchmark.add(morai_forecaster)\n",
    "benchmark.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c750be56",
   "metadata": {},
   "source": [
    "The benchmark will now evaluate:\n",
    "\n",
    "* All forecasters defined in the M4 monthly catalogue\n",
    "\n",
    "* Plus the newly added `MOIRAIForecaster`\n",
    "\n",
    "* On the same dataset, metric (OWA), and evaluation protocol\n",
    "\n",
    "Just like forecasters, any task (dataset, metric, CV splitter) can be added to the benchmark object to extend the benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63059840",
   "metadata": {},
   "source": [
    "## Using a different M4 frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62266474",
   "metadata": {},
   "source": [
    "To benchmark a different temporal granularity, simply replace `M4CompetitionCatalogueMonthly` with another M4 catalogue, for example:\n",
    "\n",
    "`M4CompetitionCatalogueHourly`\n",
    "\n",
    "`M4CompetitionCatalogueDaily`\n",
    "\n",
    "`M4CompetitionCatalogueWeekly`\n",
    "\n",
    "`M4CompetitionCatalogueQuarterly`\n",
    "\n",
    "`M4CompetitionCatalogueYearly`\n",
    "\n",
    "No other code changes are required. Each catalogue encapsulates the correct dataset, seasonal period, and evaluation metric for its frequency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sktime-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
