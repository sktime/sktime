{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Time series classification with sktime\n",
    "\n",
    "The time series classification (TSC) task involves training a model from a collection\n",
    " of time series (real valued, ordered, data) in order to predict a target variable.\n",
    " For example, we might want to build a model that can predict whether a patient is\n",
    " sick based on the ECG reading, or predict whether a device will fail based on some\n",
    " sensor reading. This notebook gives a quick guide to get you started"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data sets and problem types\n",
    "\n",
    "The UCR/UEA [time series classification archive](https://timeseriesclassification.com/)\n",
    "contains a large number of example TSC problems that have been used thousands of times\n",
    "in the literature to assess TSC algorithms. These dataset have certain\n",
    "characteristics that influence what data structure we use to store them in memory.\n",
    "\n",
    "Most datasets in the archive contain time series all of the same length. For example, \n",
    "the [arrow\n",
    "head dataset](https://timeseriesclassification.com/description.php?Dataset=ArrowHead) consists of outlines of the images of arrow heads. The\n",
    "classification of projectile points is an important topic in anthropology.\n",
    "<img src=\"./img/arrow-heads.png\" width=\"400\" alt=\"arrow heads\">\n",
    "\n",
    "The shapes of the projectile points are converted into a sequence using the\n",
    "angle-based method as described in this [blog post](https://izbicki.me/blog/converting-images-into-time-series-for-data-mining.html) about converting images into time series for data mining.\n",
    "\n",
    "<img src=\"./img/from-shapes-to-time-series.png\" width=\"400\" alt=\"from shapes to time series\">\n",
    "\n",
    "Each instance consists of a single time series (i.e. the problem is univariate) of\n",
    "equal length and a class label based on shape distinctions such as the presence and\n",
    "location of a notch in the arrow. The data set consists of 210 instances, by\n",
    "default split into 36 train and 175 test instances. We refer to the collection of\n",
    "time series as $X$ and to the collection of class labels as $y$. This type of dataset\n",
    " is most naturally stored in a two dimensional numpy array for $X$ and one\n",
    " dimensional numpy array for $y$. for the single problem loader load arrow head, set \n",
    " the return type to numpy2d or numpyflat to store $X$ in a 2D ndarray. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Imports used in this notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sktime.classification.compose import ColumnEnsembleClassifier\n",
    "from sktime.classification.dictionary_based import TemporalDictionaryEnsemble\n",
    "from sktime.classification.hybrid import HIVECOTEV2\n",
    "from sktime.classification.interval_based import DrCIF\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from sktime.datasets import (\n",
    "    load_arrow_head,\n",
    "    load_basic_motions,\n",
    "    load_japanese_vowels,\n",
    "    load_plaid,\n",
    ")\n",
    "from sktime.transformations.panel.compose import ColumnConcatenator\n",
    "from sktime.transformations.panel.tsfresh import TSFreshFeatureExtractor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Random train set for a two class problem with 10 instances of length 50\n",
    "random_train_X = np.random.rand(10, 50)\n",
    "random_train_y = np.random.randint(low=0, high=2, size=10)\n",
    "\n",
    "# Load all arrow head\n",
    "arrow_X, arrow_y = load_arrow_head(return_type=\"numpy2d\")\n",
    "# Load default train/test splits from sktime/datasets/data\n",
    "arrow_train_X, arrow_train_y = load_arrow_head(split=\"train\", return_type=\"numpy2d\")\n",
    "arrow_test_X, arrow_test_y = load_arrow_head(split=\"test\", return_type=\"numpyflat\")\n",
    "print(arrow_train_X.shape, arrow_train_y.shape, arrow_test_X.shape, arrow_test_y.shape)\n",
    "plt.title(\" First instance in ArrowHead data\")\n",
    "plt.plot(arrow_train_X[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some TSC datasets are multivariate, in that each instance has more than one\n",
    "associated time series. For example, the data [basic motions dataset]\n",
    "(https://timeseriesclassification.com/description.php?Dataset=BasicMotions)\n",
    " was generated as part of a student project where four students performed\n",
    "four activities whilst wearing a smart watch. The watch collects 3D accelerometer and\n",
    " a 3D gyroscope. Each instance involved a subject performing one of four tasks (walking,\n",
    " resting, running and badminton) for ten seconds. The data has 6 dimensions. This \n",
    " type of data is best stored as a three dimensional numpy array. To get a data \n",
    " structure of this type from the single problem loader, use the return type argument \n",
    " numpy3d as follows."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Random train set for a multivariate two class problem with 10 instances of length 50\n",
    "random_train_X = np.random.rand(10, 6, 50)\n",
    "random_train_y = np.random.randint(low=0, high=2, size=10)\n",
    "\n",
    "motions_X, motions_Y = load_basic_motions(return_type=\"numpy3d\")\n",
    "motions_train_X, motions_train_y = load_basic_motions(\n",
    "    split=\"train\", return_type=\"numpy3d\"\n",
    ")\n",
    "motions_test_X, motions_test_y = load_basic_motions(split=\"test\", return_type=\"numpy3d\")\n",
    "print(type(motions_train_X))\n",
    "print(\n",
    "    motions_train_X.shape,\n",
    "    motions_train_y.shape,\n",
    "    motions_test_X.shape,\n",
    "    motions_test_y.shape,\n",
    ")\n",
    "plt.title(\" First and second dimensions of the first instance in BasicMotions data\")\n",
    "plt.plot(motions_train_X[0][0])\n",
    "plt.plot(motions_train_X[0][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some data sets have unequal length series. Two data sets with this characteristic\n",
    "are shipped with sktime: PLAID (univariate) and JapaneseVowels (multivariate). We\n",
    "cannot store unequal length series in numpy arrays. Instead, we use nested pandas\n",
    "data frames, where each cell is a pandas Series. This is the default return type for \n",
    "all single problem loaders."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# loads both train and test together\n",
    "vowel_X, vowel_y = load_japanese_vowels()\n",
    "print(type(vowel_X))\n",
    "\n",
    "plt.title(\" First two dimensions of two instances of Japanese vowels\")\n",
    "plt.plot(vowel_X.iloc[0, 0])\n",
    "plt.plot(vowel_X.iloc[1, 0])\n",
    "plt.plot(vowel_X.iloc[0, 1])\n",
    "plt.plot(vowel_X.iloc[1, 1])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plaid_X, plaid_y = load_plaid()\n",
    "print(type(plaid_X))\n",
    "\n",
    "plt.title(\" Four instances of PLAID dataset\")\n",
    "plt.plot(plaid_X.iloc[0, 0])\n",
    "plt.plot(plaid_X.iloc[1, 0])\n",
    "plt.plot(plaid_X.iloc[2, 0])\n",
    "plt.plot(plaid_X.iloc[3, 0])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building Classifiers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We demonstrate the simplest use cases for classifiers and demonstrate how it is\n",
    "possible to compose a bespoke pipeline classifier. You can use a standard sklearn\n",
    "classifier for univariate, equal length classification problems but it is unlikely to\n",
    " perform as well as bespoke time series classifiers. You cannot use sklearn\n",
    " classifiers directly with multivariate or unequal length data\n",
    "sets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100)\n",
    "classifier.fit(arrow_train_X, arrow_train_y)\n",
    "y_pred = classifier.predict(arrow_test_X)\n",
    "accuracy_score(arrow_test_y, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "sktime contains the state of the art in time series classifiers in the package\n",
    "classification. These are grouped based on their representation. An accurate and\n",
    "relatively fast classifier is called [ROCKET](https://arxiv.org/abs/1910.13051)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rocket = RocketClassifier()\n",
    "rocket.fit(arrow_train_X, arrow_train_y)\n",
    "y_pred = rocket.predict(arrow_test_X)\n",
    "accuracy_score(arrow_test_y, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The current state of the art for TSC is version 2 of the [HIVE-COTE algorithm](https://link.springer.com/article/10.1007/s10994-021-06057-9). HC2 is slow on small\n",
    "problems like these examples. However, it can be configured with an approximate\n",
    "maximum run time as follows (may take a bit longer than a minute to run this cell)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hc2 = HIVECOTEV2(time_limit_in_minutes=1)\n",
    "hc2.fit(arrow_train_X, arrow_train_y)\n",
    "y_pred = hc2.predict(arrow_test_X)\n",
    "accuracy_score(arrow_test_y, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Most classifiers in sktime involve some degree of transformation. The simplest form\n",
    "is simply consisting of a pipeline of transformation followed by an sklearn\n",
    "classifier. You can combine transformers and classifiers in a simple pipeline. for\n",
    "example, you may want to use [tsfresh](https://tsfresh.readthedocs.io/en/latest/) to\n",
    "extract features for a random forest classifier. This can be done with sktime\n",
    "transformers as follows:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tsfresh = TSFreshFeatureExtractor(default_fc_parameters=\"minimal\")\n",
    "randf = RandomForestClassifier(n_estimators=100)\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"transform\", tsfresh),\n",
    "        (\"classifier\", randf),\n",
    "    ]\n",
    ")\n",
    "pipe.fit(arrow_train_X, arrow_train_y)\n",
    "y_pred = pipe.predict(arrow_test_X)\n",
    "accuracy_score(arrow_test_y, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multivariate classification\n",
    "Many classifiers, including ROCKET and HC2, are configured to work with multivariate\n",
    "input. For example"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rocket.fit(motions_train_X, motions_train_y)\n",
    "y_pred = rocket.predict(motions_test_X)\n",
    "accuracy_score(motions_test_y, y_pred)\n",
    "hc2.fit(motions_train_X, motions_train_y)\n",
    "y_pred = hc2.predict(motions_test_X)\n",
    "accuracy_score(motions_test_y, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "sktime offers two other ways of solving multivariate time series classification \n",
    "problems:\n",
    "\n",
    "1. Concatenation of time series columns into a single long time series column via \n",
    "`ColumnConcatenator` and apply a classifier to the concatenated data,\n",
    "2. Dimensiion ensembling via `ColumnEnsembleClassifier` in which one classifier is\n",
    " fitted for each time series column/dimension of the time series and their predictions \n",
    " are combined through a voting scheme. \n",
    "\n",
    "We can concatenate multivariate time series/panel data into long univariate time \n",
    "series/panel using a tran and then apply a classifier to the univariate data.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "steps = [\n",
    "    (\"concatenate\", ColumnConcatenator()),\n",
    "    (\"classify\", DrCIF(n_estimators=10)),\n",
    "]\n",
    "clf = Pipeline(steps)\n",
    "clf.fit(motions_train_X, motions_train_y)\n",
    "clf.score(motions_test_X, motions_test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also fit one classifier for each time series column and then aggregated their \n",
    "predictions. The interface is similar to the familiar `ColumnTransformer` from sklearn."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = ColumnEnsembleClassifier(\n",
    "    estimators=[\n",
    "        (\"DrCIF0\", DrCIF(n_estimators=10), [0]),\n",
    "        (\"TDE3\", TemporalDictionaryEnsemble(max_ensemble_size=5), [3]),\n",
    "    ]\n",
    ")\n",
    "clf.fit(motions_train_X, motions_train_y)\n",
    "clf.score(motions_test_X, motions_test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Background info and references for classifiers used here\n",
    "\n",
    "#### The RocketClassifier \n",
    "is based on a pipeline combination of the ROCKET transformation (transformations\n",
    ".panel.rocket) and the sklearn RidgeClassifierCV classifier. The RocketClassifier is \n",
    "configurable to use variants minirocket and multirocket. ROCKET is based on \n",
    "generating random convolutions. A large number are generated then the classifier \n",
    "performs a feature selection.\n",
    "\n",
    "[1] Dempster, Angus, François Petitjean, and Geoffrey I. Webb. \"Rocket:\n",
    "       exceptionally fast and accurate time series classification using random\n",
    "       convolutional kernels.\" Data Mining and Knowledge Discovery 34.5 (2020)\n",
    "[arXiv version](https://arxiv.org/abs/1910.13051)\n",
    "\n",
    "#### DrCIF\n",
    "The Diverse Representation Canonical Interval Forest Classifier (DrCIF) is an \n",
    "interval based classifier. The algorithm takes multiple randomised intervals from \n",
    "each series and extracts a range of features. These features are used to build a \n",
    "decision tree, which in turn are ensembled into a decision forest, in the style of a \n",
    "random forest. The original version \n",
    "\n",
    "[2] Matthew Middlehurst and James Large and Anthony Bagnall. \"The Canonical\n",
    "       Interval Forest (CIF) Classifier for Time Series Classification.\"\n",
    "       IEEE International Conference on Big Data 2020\n",
    "[arXiv version](https://arxiv.org/abs/2008.09172)\n",
    "\n",
    "The DrCIF adjustment was proposed in [4]        \n",
    "#### TDE\n",
    "he Temporal Dictionary Ensemble is a dictionary based classifier. The basic premise \n",
    "is to extract discrete patterns using a windowing and to count their occurence. \n",
    "Classification is based on these frequency histograms. TDE includes bigram \n",
    "frequencies, spatial pyramids and a Gaussian process based parameter search. \n",
    "\n",
    "[3] Matthew Middlehurst, James Large, Gavin Cawley and Anthony Bagnall\n",
    "        \"The Temporal Dictionary Ensemble (TDE) Classifier for Time Series\n",
    "        Classification\", in proceedings of the European Conference on Machine Learning\n",
    "        and Principles and Practice of Knowledge Discovery in Databases, 2020.\n",
    "[arXiv version](https://arxiv.org/abs/2105.03841)\n",
    "\n",
    "#### HiveCoteV2 (HC2)\n",
    "\n",
    "The HIerarchical VotE Collective of Transformation-based Ensembles is a meta ensemble\n",
    " that combines classifiers built on different representations. Version 2 \n",
    " combines DrCIF, TDE, an ensemble of RocketClassifiers called the Arsenal and the \n",
    " ShapeletTransformClassifier. It is currently the most accurate classifier on the UCR\n",
    "  and UEA time series archives. \n",
    "   \n",
    "[4] Middlehurst, Matthew, James Large, Michael Flynn, Jason Lines, Aaron Bostrom,\n",
    "       and Anthony Bagnall. \"HIVE-COTE 2.0: a new meta ensemble for time series\n",
    "       classification.\" [Machine Learning (2021)](https://link.springer.com/article/10.1007/s10994-021-06057-9)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
