{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reframing VAR Model Fitting: From Linear Regression to Regularized Approaches\n",
    "\n",
    "Vector Autoregression (VAR) is a statistical model used to understand how multiple time series influence each other over time. It uses past values (lags) of these time series to predict their current values.\n",
    "\n",
    "In this article, we'll explore how the familiar Ordinary Least Squares (OLS) linear regression underpins the VAR fitting process. Recognizing this connection allows us to reframe VAR fitting as a two-step process: tabularization followed by linear regression. By breaking down VAR fitting into these two steps, we gain flexibility in the regression step, enabling us to leverage regressors other than OLS regressor, such as those that offer regularization. We will also introduce a new `sktime` estimator, `VARReduce`, that explicitly implements these two-step process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error\n",
    "from sktime.forecasting.var_reduce import VARReduce\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sktime.forecasting.compose import TransformedTargetForecaster\n",
    "from sktime.forecasting.compose import ForecastingPipeline\n",
    "from sktime.transformations.series.adapt import TabularToSeriesAdaptor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate our models, we shall first generate a small synthetic multivariate time series dataset. \n",
    "\n",
    "We create three time series, each with 100 observations, and store them in a DataFrame. \n",
    "\n",
    "We then split the data into training and testing sets, reserving the last 5 observations for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts1</th>\n",
       "      <th>ts2</th>\n",
       "      <th>ts3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestep</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1496.714153</td>\n",
       "      <td>-41.537074</td>\n",
       "      <td>13.577874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>861.735699</td>\n",
       "      <td>57.935468</td>\n",
       "      <td>15.607845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1647.688538</td>\n",
       "      <td>65.728548</td>\n",
       "      <td>20.830512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2523.029856</td>\n",
       "      <td>19.772273</td>\n",
       "      <td>20.538021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>765.846625</td>\n",
       "      <td>83.871429</td>\n",
       "      <td>-3.776694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ts1        ts2        ts3\n",
       "timestep                                   \n",
       "1         1496.714153 -41.537074  13.577874\n",
       "2          861.735699  57.935468  15.607845\n",
       "3         1647.688538  65.728548  20.830512\n",
       "4         2523.029856  19.772273  20.538021\n",
       "5          765.846625  83.871429  -3.776694"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "n_obs = 100\n",
    "time_series_1 = np.random.randn(n_obs)*1000 + 1000\n",
    "time_series_2 = np.random.randn(n_obs)*100 + 100\n",
    "time_series_3 = np.random.randn(n_obs)*10 + 10\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"ts1\": time_series_1,\n",
    "        \"ts2\": time_series_2,\n",
    "        \"ts3\": time_series_3,\n",
    "    }, index = range(1, n_obs + 1)\n",
    ")\n",
    "\n",
    "df.index.name = \"timestep\"\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "df_train, df_test = temporal_train_test_split(df, test_size=5)\n",
    "\n",
    "# Showing the first 5 rows of the train set\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's revisit the concept of a Vector Autoregressive (VAR) model. A VAR model of order $p$ (denoted as VAR $p$ describes the relationship between multiple time series variables $y_{1,t}, y_{2,t}, \\ldots, y_{k,t}$. The model is expressed as:\n",
    "\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "y_{1,t} &= c_1 + \\sum_{j=1}^{k} \\sum_{l=1}^{p} \\beta_{1j,l} y_{j,t-l} + \\epsilon_{1,t}, \\\\\n",
    "y_{2,t} &= c_2 + \\sum_{j=1}^{k} \\sum_{l=1}^{p} \\beta_{2j,l} y_{j,t-l} + \\epsilon_{2,t}, \\\\\n",
    "&\\vdots \\\\\n",
    "y_{k,t} &= c_k + \\sum_{j=1}^{k} \\sum_{l=1}^{p} \\beta_{kj,l} y_{j,t-l} + \\epsilon_{k,t}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "Here:\n",
    "- $y_{i,t}$ represents the value of the $i$-th time series at time $t$.\n",
    "- $c_i$ denotes the intercept for the $i$-th equation.\n",
    "- $\\beta_{ij,l}$ are the coefficients representing the influence of the $l$-lagged value of the $j$-th variable on the $i$-th variable.\n",
    "- $\\epsilon_{i,t}$ are the error terms (or residuals) associated with each equation.\n",
    "\n",
    "In essence, fitting a VAR model involves estimating multiple linear regression equations simultaneously. Each time series is modeled as a linear function of its own past values and the past values of the other time series in the system. The current value of each time series depends on the lagged values of all $k$ time series, creating a system of interconnected equations.\n",
    "\n",
    "A widely-used implementation of the VAR model in Python is found in the `statsmodels` library. If you delve into the source code of `statsmodels`' `VAR`, you'll discover that it implicitly tabularizes the time series data and leverages OLS through the `np.linalg.lstsq` function to estimate the model parameters. Below, we instantiate and fit a VAR model to our data, which we will then compare with the `VARReduce` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lags\n",
    "LAGS = 2\n",
    "\n",
    "# Fit the VAR model using statsmodels for comparison\n",
    "var_model = VAR(df_train)\n",
    "results = var_model.fit(LAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `VARReduce` is a new `sktime` implementation of VAR. Its `fitting` works by first explicitly converting multivariate time series data into a tabular format suitable for regression models. This intermediate table can be extracted out using the `prepare_var_data` method from the `VARReduce` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-71cca58e-49cb-463b-8199-60018dc19d48 {color: black;background-color: white;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 pre{padding: 0;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-toggleable {background-color: white;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-estimator:hover {background-color: #d4ebff;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-item {z-index: 1;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-parallel-item:only-child::after {width: 0;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-71cca58e-49cb-463b-8199-60018dc19d48 div.sk-text-repr-fallback {display: none;}</style><div id='sk-71cca58e-49cb-463b-8199-60018dc19d48' class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VARReduce(lags=2)</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class='sk-item'><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=UUID('007447d7-0dd1-48cb-a1ea-3e51820e3a0f') type=\"checkbox\" checked><label for=UUID('007447d7-0dd1-48cb-a1ea-3e51820e3a0f') class='sk-toggleable__label sk-toggleable__label-arrow'>VARReduce</label><div class=\"sk-toggleable__content\"><pre>VARReduce(lags=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "VARReduce(lags=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit the custom VARReduce model\n",
    "varreduce_model = VARReduce(lags=LAGS)  # no regressor passed, by default, LinearRegressor() will be used\n",
    "varreduce_model.fit(df_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally, `VARReduce` transforms the provided training data into a tabular format suitable for regression. Specifically:\n",
    "\n",
    "1. **Predictors (X)**: The predictors consist of lagged values of the time series, with the number of lags specified by the `lags` parameter. In the displayed DataFrame, each column represents a lagged value for one of the time series (e.g., `ts1_lag1`, `ts2_lag2`).\n",
    "\n",
    "2. **Target Variables (Y)**: The target variables are the current, unlagged values of the time series.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts1</th>\n",
       "      <th>ts2</th>\n",
       "      <th>ts3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestep</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1647.688538</td>\n",
       "      <td>65.728548</td>\n",
       "      <td>20.830512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2523.029856</td>\n",
       "      <td>19.772273</td>\n",
       "      <td>20.538021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>765.846625</td>\n",
       "      <td>83.871429</td>\n",
       "      <td>-3.776694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>765.863043</td>\n",
       "      <td>140.405086</td>\n",
       "      <td>0.621750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2579.212816</td>\n",
       "      <td>288.618590</td>\n",
       "      <td>15.150353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ts1         ts2        ts3\n",
       "timestep                                    \n",
       "3         1647.688538   65.728548  20.830512\n",
       "4         2523.029856   19.772273  20.538021\n",
       "5          765.846625   83.871429  -3.776694\n",
       "6          765.863043  140.405086   0.621750\n",
       "7         2579.212816  288.618590  15.150353"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = varreduce_model.prepare_for_fit(df_train, return_as_ndarray=False)\n",
    "Y.head() \n",
    "# `Y` is identical to our `df_train` but with the first 2 rows (the earliest data) left out \n",
    "# as no corresponding lagged value its available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts1_lag1</th>\n",
       "      <th>ts2_lag1</th>\n",
       "      <th>ts3_lag1</th>\n",
       "      <th>ts1_lag2</th>\n",
       "      <th>ts2_lag2</th>\n",
       "      <th>ts3_lag2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestep</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>861.735699</td>\n",
       "      <td>57.935468</td>\n",
       "      <td>15.607845</td>\n",
       "      <td>1496.714153</td>\n",
       "      <td>-41.537074</td>\n",
       "      <td>13.577874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1647.688538</td>\n",
       "      <td>65.728548</td>\n",
       "      <td>20.830512</td>\n",
       "      <td>861.735699</td>\n",
       "      <td>57.935468</td>\n",
       "      <td>15.607845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2523.029856</td>\n",
       "      <td>19.772273</td>\n",
       "      <td>20.538021</td>\n",
       "      <td>1647.688538</td>\n",
       "      <td>65.728548</td>\n",
       "      <td>20.830512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>765.846625</td>\n",
       "      <td>83.871429</td>\n",
       "      <td>-3.776694</td>\n",
       "      <td>2523.029856</td>\n",
       "      <td>19.772273</td>\n",
       "      <td>20.538021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>765.863043</td>\n",
       "      <td>140.405086</td>\n",
       "      <td>0.621750</td>\n",
       "      <td>765.846625</td>\n",
       "      <td>83.871429</td>\n",
       "      <td>-3.776694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ts1_lag1    ts2_lag1   ts3_lag1     ts1_lag2   ts2_lag2  \\\n",
       "timestep                                                               \n",
       "3          861.735699   57.935468  15.607845  1496.714153 -41.537074   \n",
       "4         1647.688538   65.728548  20.830512   861.735699  57.935468   \n",
       "5         2523.029856   19.772273  20.538021  1647.688538  65.728548   \n",
       "6          765.846625   83.871429  -3.776694  2523.029856  19.772273   \n",
       "7          765.863043  140.405086   0.621750   765.846625  83.871429   \n",
       "\n",
       "           ts3_lag2  \n",
       "timestep             \n",
       "3         13.577874  \n",
       "4         15.607845  \n",
       "5         20.830512  \n",
       "6         20.538021  \n",
       "7         -3.776694  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()\n",
    "# These are the corresponding lagged values for each time steps for each series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is prepared in this tabular format, `VARReduce` trains a regressor on it. By default, `LinearRegression` from scikit-learn is used as the regressor. Under these default conditions, the `VARReduce` model behaves just like a traditional VAR model. This means that the fitted coefficients and the resulting forecasts will be identical to those of a VAR model, as both are essentially performing linear regression on the same lagged data.\n",
    "\n",
    "This equivalence is demonstrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients from VARReduce model:\n",
      "[[[-4.37961558e-02 -1.43626262e+00 -2.86812433e+00]\n",
      "  [-2.69100197e-03 -1.23887306e-01 -9.70235652e-01]\n",
      "  [-2.88434936e-04 -1.27713432e-02 -1.13313395e-01]]\n",
      "\n",
      " [[-4.88786990e-02 -5.36461965e-01 -1.24494180e+00]\n",
      "  [ 1.19199535e-02 -5.73508122e-02 -1.32217511e+00]\n",
      "  [ 9.30698995e-04  9.74401474e-03 -3.91534996e-02]]]\n",
      "\n",
      "Coefficients from statsmodels VAR:\n",
      "[[[-4.37961558e-02 -1.43626262e+00 -2.86812433e+00]\n",
      "  [-2.69100197e-03 -1.23887306e-01 -9.70235652e-01]\n",
      "  [-2.88434936e-04 -1.27713432e-02 -1.13313395e-01]]\n",
      "\n",
      " [[-4.88786990e-02 -5.36461965e-01 -1.24494180e+00]\n",
      "  [ 1.19199535e-02 -5.73508122e-02 -1.32217511e+00]\n",
      "  [ 9.30698995e-04  9.74401474e-03 -3.91534996e-02]]]\n",
      "\n",
      "Are the coefficients from VARReduce and sktime VAR essentially the same?  True\n"
     ]
    }
   ],
   "source": [
    "# Compare coefficients\n",
    "print(\"Coefficients from VARReduce model:\")\n",
    "print(varreduce_model.coefficients_)\n",
    "\n",
    "print(\"\\nCoefficients from statsmodels VAR:\")\n",
    "print(results.coefs)\n",
    "\n",
    "epsilon = 1e-8\n",
    "coefs_are_close = np.allclose(varreduce_model.coefficients_, results.coefs, atol=epsilon)\n",
    "print(\"\\nAre the coefficients from VARReduce and sktime VAR essentially the same? \", coefs_are_close)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the two models have essentially identical fitted parameters, it is unsurprising that their forecasts are also essentially identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([96, 97, 98, 99, 100], dtype='int64', name='timestep')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the forecasting horizon - 5 data points (same as our df_test)\n",
    "fh = ForecastingHorizon(df_test.index, is_relative=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ForecastingHorizon([1, 2, 3, 4, 5], dtype='int64', name='timestep', is_relative=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fh_int = fh.to_relative(varreduce_model.cutoff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions from VARReduce model:\n",
      "                 ts1         ts2        ts3\n",
      "timestep                                   \n",
      "96        954.059678   95.999686   8.159195\n",
      "97        918.199802  100.566178  10.460230\n",
      "98        907.864603  110.367569  10.477824\n",
      "99        890.627791  105.432332  10.274662\n",
      "100       894.278881  105.578669  10.450881\n",
      "\n",
      "Predictions from statsmodels VAR:\n",
      "[[954.05967783  95.99968573   8.15919522]\n",
      " [918.1998017  100.5661778   10.46022974]\n",
      " [907.86460253 110.36756925  10.4778239 ]\n",
      " [890.62779088 105.43233217  10.274662  ]\n",
      " [894.27888074 105.57866919  10.45088134]]\n",
      "\n",
      "Are the predictions from VARReduce and sktime VAR essentially the same?  True\n"
     ]
    }
   ],
   "source": [
    "# Define the forecasting horizon - 5 data points (same as our df_test)\n",
    "fh = ForecastingHorizon(df_test.index, is_relative=False)\n",
    "\n",
    "# Generating forecasts from both models\n",
    "df_pred_varreduce = varreduce_model.predict(fh=fh)\n",
    "df_pred_statsmodels = results.forecast(df_train.values[-LAGS:], steps=len(fh))\n",
    "\n",
    "# Compare coefficients\n",
    "print(\"Predictions from VARReduce model:\")\n",
    "print(df_pred_varreduce)\n",
    "\n",
    "print(\"\\nPredictions from statsmodels VAR:\")\n",
    "print(df_pred_statsmodels)\n",
    "\n",
    "# Compare predictions using numpy's allclose function\n",
    "epsilon = 1e-8\n",
    "predictions_are_close = np.allclose(df_pred_varreduce, df_pred_statsmodels, atol=epsilon)\n",
    "print(\"\\nAre the predictions from VARReduce and sktime VAR essentially the same? \", predictions_are_close)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A benefit of `VARReduce` vis-a-vis `VAR` is that in the former, we are not restricted to using only `LinearRegressor` as the regressor. In fact, the user can specify any other `scikit-learn` compatible regressors to introduce regularization, which can potentially enhance performance for large datasets or when multicollinearity is present. Below are two examples:\n",
    "\n",
    "1. **Ridge Regression (L2 Regularization)**:\n",
    "   Ridge model adds a penalty proportional to the sum of the squares of the coefficients.\n",
    "   It helps prevent overfitting by shrinking the coefficients.\n",
    "\n",
    "     $$\n",
    "     \\min_{\\beta} \\sum_{i=1}^{n} (y_i - X_i \\beta)^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2\n",
    "     $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts1</th>\n",
       "      <th>ts2</th>\n",
       "      <th>ts3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestep</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>954.077519</td>\n",
       "      <td>96.013428</td>\n",
       "      <td>8.159868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>918.176153</td>\n",
       "      <td>100.566330</td>\n",
       "      <td>10.459893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>907.853466</td>\n",
       "      <td>110.363246</td>\n",
       "      <td>10.477869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>890.636145</td>\n",
       "      <td>105.433211</td>\n",
       "      <td>10.274717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>894.279962</td>\n",
       "      <td>105.578644</td>\n",
       "      <td>10.450806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ts1         ts2        ts3\n",
       "timestep                                   \n",
       "96        954.077519   96.013428   8.159868\n",
       "97        918.176153  100.566330  10.459893\n",
       "98        907.853466  110.363246  10.477869\n",
       "99        890.636145  105.433211  10.274717\n",
       "100       894.279962  105.578644  10.450806"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "varreduce_model_ridge = VARReduce(lags=LAGS,\n",
    "                                  regressor = Ridge(alpha = 10)) \n",
    "varreduce_model_ridge.fit(df_train)\n",
    "varreduce_model_ridge.predict(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "2. **Lasso Regression (L1 Regularization)**:\n",
    "   The Lasso model adds a penalty proportional to the sum of the absolute values of the coefficients.\n",
    "   It can drive some coefficients to zero, effectively performing variable selection.\n",
    "\n",
    "     $$\n",
    "     \\min_{\\beta} \\sum_{i=1}^{n} (y_i - X_i \\beta)^2 + \\lambda \\sum_{j=1}^{p} |\\beta_j|\n",
    "     $$\n",
    "\n",
    "\n",
    "#### Citations\n",
    "\n",
    "- Lütkepohl, H. (2005). \"New Introduction to Multiple Time Series Analysis\". Springer. This book offers an in-depth discussion on the theory and application of VAR models, including their equivalence to multiple linear regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-4.48306604e-02, -1.41189355e+00, -1.89058754e+00],\n",
       "        [-3.72170608e-03, -9.95940869e-02, -0.00000000e+00],\n",
       "        [-4.00822026e-04, -2.24104956e-03, -0.00000000e+00]],\n",
       "\n",
       "       [[-5.00755076e-02, -5.12208830e-01, -2.63878913e-01],\n",
       "        [ 1.04728950e-02, -3.35218198e-02, -3.38272978e-01],\n",
       "        [ 6.79201910e-04,  9.58324326e-04, -0.00000000e+00]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "varreduce_model_lasso = VARReduce(lags=LAGS,\n",
    "                                  regressor = Lasso(alpha = 100))  \n",
    "varreduce_model_lasso.fit(df_train)\n",
    "varreduce_model_lasso.coefficients_\n",
    "# We note below how some coefficients are driven to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts1</th>\n",
       "      <th>ts2</th>\n",
       "      <th>ts3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestep</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>962.865324</td>\n",
       "      <td>104.917391</td>\n",
       "      <td>10.194001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>902.691692</td>\n",
       "      <td>101.066194</td>\n",
       "      <td>10.171717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>900.336092</td>\n",
       "      <td>106.949055</td>\n",
       "      <td>10.433682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>896.632178</td>\n",
       "      <td>105.878369</td>\n",
       "      <td>10.376881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>895.452886</td>\n",
       "      <td>105.688298</td>\n",
       "      <td>10.384803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ts1         ts2        ts3\n",
       "timestep                                   \n",
       "96        962.865324  104.917391  10.194001\n",
       "97        902.691692  101.066194  10.171717\n",
       "98        900.336092  106.949055  10.433682\n",
       "99        896.632178  105.878369  10.376881\n",
       "100       895.452886  105.688298  10.384803"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varreduce_model_lasso.predict(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Real World Macreconomic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The power of `VARReduce` becomes more evident when dealing with real-world datasets containing numerous time series. An example is the `macrodata` dataset, which contains 14 variables. This dataset is loaded below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>realgdp</th>\n",
       "      <th>realcons</th>\n",
       "      <th>realinv</th>\n",
       "      <th>realgovt</th>\n",
       "      <th>realdpi</th>\n",
       "      <th>cpi</th>\n",
       "      <th>m1</th>\n",
       "      <th>tbilrate</th>\n",
       "      <th>unemp</th>\n",
       "      <th>pop</th>\n",
       "      <th>infl</th>\n",
       "      <th>realint</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1959Q1</th>\n",
       "      <td>2710.349</td>\n",
       "      <td>1707.4</td>\n",
       "      <td>286.898</td>\n",
       "      <td>470.045</td>\n",
       "      <td>1886.9</td>\n",
       "      <td>28.98</td>\n",
       "      <td>139.7</td>\n",
       "      <td>2.82</td>\n",
       "      <td>5.8</td>\n",
       "      <td>177.146</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959Q2</th>\n",
       "      <td>2778.801</td>\n",
       "      <td>1733.7</td>\n",
       "      <td>310.859</td>\n",
       "      <td>481.301</td>\n",
       "      <td>1919.7</td>\n",
       "      <td>29.15</td>\n",
       "      <td>141.7</td>\n",
       "      <td>3.08</td>\n",
       "      <td>5.1</td>\n",
       "      <td>177.830</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959Q3</th>\n",
       "      <td>2775.488</td>\n",
       "      <td>1751.8</td>\n",
       "      <td>289.226</td>\n",
       "      <td>491.260</td>\n",
       "      <td>1916.4</td>\n",
       "      <td>29.35</td>\n",
       "      <td>140.5</td>\n",
       "      <td>3.82</td>\n",
       "      <td>5.3</td>\n",
       "      <td>178.657</td>\n",
       "      <td>2.74</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959Q4</th>\n",
       "      <td>2785.204</td>\n",
       "      <td>1753.7</td>\n",
       "      <td>299.356</td>\n",
       "      <td>484.052</td>\n",
       "      <td>1931.3</td>\n",
       "      <td>29.37</td>\n",
       "      <td>140.0</td>\n",
       "      <td>4.33</td>\n",
       "      <td>5.6</td>\n",
       "      <td>179.386</td>\n",
       "      <td>0.27</td>\n",
       "      <td>4.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960Q1</th>\n",
       "      <td>2847.699</td>\n",
       "      <td>1770.5</td>\n",
       "      <td>331.722</td>\n",
       "      <td>462.199</td>\n",
       "      <td>1955.5</td>\n",
       "      <td>29.54</td>\n",
       "      <td>139.6</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.2</td>\n",
       "      <td>180.007</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         realgdp  realcons  realinv  realgovt  realdpi    cpi     m1  \\\n",
       "date                                                                   \n",
       "1959Q1  2710.349    1707.4  286.898   470.045   1886.9  28.98  139.7   \n",
       "1959Q2  2778.801    1733.7  310.859   481.301   1919.7  29.15  141.7   \n",
       "1959Q3  2775.488    1751.8  289.226   491.260   1916.4  29.35  140.5   \n",
       "1959Q4  2785.204    1753.7  299.356   484.052   1931.3  29.37  140.0   \n",
       "1960Q1  2847.699    1770.5  331.722   462.199   1955.5  29.54  139.6   \n",
       "\n",
       "        tbilrate  unemp      pop  infl  realint  \n",
       "date                                             \n",
       "1959Q1      2.82    5.8  177.146  0.00     0.00  \n",
       "1959Q2      3.08    5.1  177.830  2.34     0.74  \n",
       "1959Q3      3.82    5.3  178.657  2.74     1.09  \n",
       "1959Q4      4.33    5.6  179.386  0.27     4.06  \n",
       "1960Q1      3.50    5.2  180.007  2.31     1.19  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the macrodata dataset using statsmodels\n",
    "dataset = sm.datasets.macrodata.load_pandas()\n",
    "df = dataset.data\n",
    "df['year'] = df['year'].astype(int)\n",
    "df['quarter'] = df['quarter'].astype(int)\n",
    "\n",
    "# Create a datetime column\n",
    "df['date'] = pd.to_datetime(df['year'].astype(str) + 'Q' + df['quarter'].astype(str))\n",
    "\n",
    "# Set the datetime column as the index\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Convert the datetime index to a period index with quarterly frequency\n",
    "df.index = df.index.to_period('Q')\n",
    "\n",
    "# Drop the original year and quarter columns if no longer needed\n",
    "df.drop(columns=['year', 'quarter'], inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "df_train, df_test = temporal_train_test_split(df, test_size=24)\n",
    "fh = ForecastingHorizon(df_test.index, is_relative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a traditional VAR model on this dataset with a lag of 3 means we have to fit a substantial number of parameters. Specifically, for each variable, the model needs to estimate coefficients for the current and three previous values of all 14 variables, plus an intercept. This results in a total of \\( (14 \\times 14 \\times 3) + 14 = 602 \\) parameters. Given that the number of data points is relatively small, this high number of parameters makes the model prone to overfitting, where it captures noise in the training data rather than the underlying patterns.\n",
    "\n",
    "Overfitting leads to poor generalization to new, unseen data, resulting in inaccurate forecasts. To mitigate this, regularization techniques can be applied, which is where `VARReduce` shines. By selecting a regressor with built-in regularization properties, such as Ridge regression (L2 regularization) or Lasso regression (L1 regularization), we can introduce penalties on the size of the coefficients. This effectively controls the complexity of the model, preventing overfitting, enhancing stability, and improving the forecast accuracy.\n",
    "\n",
    "For instance, using Ridge regression within `VARReduce` helps to manage multicollinearity and shrink the less important coefficients towards zero, making the model more interpretable and reliable. This ability to integrate advanced regression techniques allows `VARReduce` to leverage the flexibility and robustness of scikit-learn regressors, providing a powerful tool for time series forecasting in complex, high-dimensional datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.var import VAR\n",
    "\n",
    "# Define lags\n",
    "LAGS = 3\n",
    "\n",
    "# Create the pipeline for VARReduce\n",
    "scaler = TabularToSeriesAdaptor(StandardScaler())\n",
    "varreduce_model = VARReduce(lags=LAGS, regressor = Ridge(alpha = 10))\n",
    "pipeline_varreduce = ForecastingPipeline(steps=[(\"scaler\", scaler), (\"forecaster\", varreduce_model)])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline_varreduce.fit(df_train)\n",
    "df_pred_varreduce = pipeline_varreduce.predict(fh=fh)\n",
    "\n",
    "# Create the pipeline for VAR using sktime\n",
    "pipeline_var = ForecastingPipeline(steps=[(\"scaler\", scaler), (\"forecaster\", VAR(maxlags=LAGS))])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline_var.fit(df_train)\n",
    "df_pred_var = pipeline_var.predict(fh=fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE for VARReduce model: 0.48\n",
      "MAPE for statsmodels VAR model: 0.53\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance metrics for VARReduce\n",
    "mape_varreduce = mean_absolute_percentage_error(df_test, df_pred_varreduce)\n",
    "print(f\"MAPE for VARReduce model: {mape_varreduce:.2f}\")\n",
    "\n",
    "# Calculate performance metrics for statsmodels VAR\n",
    "mape_var = mean_absolute_percentage_error(df_test, df_pred_var)\n",
    "print(f\"MAPE for statsmodels VAR model: {mape_var:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
