{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7k8nnuo089",
   "metadata": {},
   "source": [
    "# Pretraining Forecasters on Panel Data\n",
    "\n",
    "This notebook demonstrates how to **pretrain** sktime forecasters on a collection\n",
    "of related time series before fine-tuning them on a specific target series.\n",
    "\n",
    "Pretraining is useful when you have many related series that share common temporal\n",
    "patterns. The model first learns these shared patterns from the panel, then\n",
    "adapts to a specific series with fewer observations.\n",
    "\n",
    "**Prerequisites**\n",
    "- Basic familiarity with sktime forecasting (see `01_forecasting.ipynb`)\n",
    "- Understanding of panel/hierarchical data formats (see `01c_forecasting_hierarchical_global.ipynb`)\n",
    "\n",
    "**Dependencies**\n",
    "- `sktime` (all examples)\n",
    "- `torch` (only for the `LTSFLinearForecaster` section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xq9dvcgzvh",
   "metadata": {},
   "outputs": [],
   "source": "# imports used throughout this notebook\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom sktime.datasets import load_hierarchical_sales_toydata\nfrom sktime.forecasting.base import ForecastingHorizon\nfrom sktime.forecasting.dummy_global import DummyGlobalForecaster\nfrom sktime.registry import all_estimators\nfrom sktime.utils._testing.hierarchical import _make_hierarchical"
  },
  {
   "cell_type": "markdown",
   "id": "kvy3zy98f3",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "### Pretraining vs. other approaches\n",
    "\n",
    "sktime supports several ways to leverage multiple time series. The table below\n",
    "helps decide which approach fits your use case.\n",
    "\n",
    "| Approach | Use when |\n",
    "|---|---|\n",
    "| `fit` only | You have a single series with sufficient history |\n",
    "| `pretrain` + `fit` | You have related series and want to transfer learned patterns to a target series |\n",
    "| Foundation model (Chronos, MOIRAI, ...) | You want zero-shot or few-shot forecasting from a large externally trained model |\n",
    "| Global forecasting | You want a single model that predicts **all** series jointly, without per-series fine-tuning |\n",
    "\n",
    "The key difference between pretraining and foundation models: foundation models\n",
    "ship pre-trained on massive external corpora, while the `pretrain` API lets you\n",
    "train on **your own domain data**.\n",
    "\n",
    "### Estimator state lifecycle\n",
    "\n",
    "Every sktime forecaster tracks its lifecycle phase via the `state` property.\n",
    "Pretraining introduces an intermediate state between construction and fitting:\n",
    "\n",
    "```\n",
    "             pretrain()              fit()             predict()\n",
    "   \"new\" ──────────────> \"pretrained\" ──────> \"fitted\" ──────────> ...\n",
    "     │                                           ^\n",
    "     └───────────────── fit() ───────────────────┘\n",
    "```\n",
    "\n",
    "- Calling `fit` on a `\"new\"` forecaster resets and trains from scratch (the standard workflow).\n",
    "- Calling `fit` on a `\"pretrained\"` forecaster preserves pretrained weights and fine-tunes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wh8mil6r34s",
   "metadata": {},
   "source": [
    "## Loading panel data\n",
    "\n",
    "Pretraining requires panel or hierarchical data (multiple time series instances).\n",
    "We use the hierarchical sales toy dataset: monthly sales for 4 product groups\n",
    "across 2 product lines, giving us 4 individual series with 60 time points each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "p2hnu45yje9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (240, 1)\n",
      "Index levels: ['Product line', 'Product group', 'Date']\n",
      "Unique series: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product line</th>\n",
       "      <th>Product group</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Food preparation</th>\n",
       "      <th rowspan=\"10\" valign=\"top\">Hobs</th>\n",
       "      <th>2000-01</th>\n",
       "      <td>245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02</th>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03</th>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04</th>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05</th>\n",
       "      <td>236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06</th>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-07</th>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08</th>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-09</th>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10</th>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Sales\n",
       "Product line     Product group Date          \n",
       "Food preparation Hobs          2000-01  245.0\n",
       "                               2000-02  144.0\n",
       "                               2000-03  184.0\n",
       "                               2000-04  265.0\n",
       "                               2000-05  236.0\n",
       "                               2000-06   97.0\n",
       "                               2000-07  190.0\n",
       "                               2000-08  135.0\n",
       "                               2000-09  130.0\n",
       "                               2000-10  172.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_panel = load_hierarchical_sales_toydata()\n",
    "\n",
    "print(f\"Shape: {y_panel.shape}\")\n",
    "print(f\"Index levels: {y_panel.index.names}\")\n",
    "print(f\"Unique series: {len(y_panel.index.droplevel(-1).unique())}\")\n",
    "y_panel.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adz2107gnrl",
   "source": "The plot below shows all 4 product series side by side. These are the series the\nforecaster will learn shared patterns from during pretraining.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "hvrh5j4zt9k",
   "source": "fig, ax = plt.subplots(figsize=(10, 4))\n\nseries_ids = y_panel.index.droplevel(-1).unique()\nfor series_id in series_ids:\n    series = y_panel.xs(series_id)[\"Sales\"]\n    label = \" / \".join(series_id)\n    ax.plot(series.index.to_timestamp(), series.values, label=label)\n\nax.set_title(\"Panel Data: Monthly Sales by Product Group\")\nax.set_xlabel(\"Date\")\nax.set_ylabel(\"Sales\")\nax.legend(fontsize=8)\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d8dq56m88ch",
   "metadata": {},
   "source": [
    "We also extract one specific series to use as our fine-tuning target later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "j58k6q5igl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target series length: 60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2004-08    174.0\n",
       "2004-09    146.0\n",
       "2004-10    157.0\n",
       "2004-11    113.0\n",
       "2004-12    119.0\n",
       "Freq: M, Name: Sales, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target = y_panel.xs((\"Food preparation\", \"Hobs\"))[\"Sales\"]\n",
    "print(f\"Target series length: {len(y_target)}\")\n",
    "y_target.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lrdedzg5kn",
   "source": "The target series (Food preparation / Hobs) is highlighted below. This is the\nseries we will fine-tune on after pretraining.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "uej3jjmpo4",
   "source": "fig, ax = plt.subplots(figsize=(10, 4))\n\nfor series_id in series_ids:\n    series = y_panel.xs(series_id)[\"Sales\"]\n    is_target = series_id == (\"Food preparation\", \"Hobs\")\n    ax.plot(\n        series.index.to_timestamp(),\n        series.values,\n        color=\"C0\" if is_target else \"lightgrey\",\n        linewidth=2 if is_target else 1,\n        label=\" / \".join(series_id) if is_target else None,\n    )\n\nax.set_title(\"Target Series: Food Preparation / Hobs\")\nax.set_xlabel(\"Date\")\nax.set_ylabel(\"Sales\")\nax.legend()\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "kewmerioga",
   "metadata": {},
   "source": [
    "## Example 1: DummyGlobalForecaster (no deep learning)\n",
    "\n",
    "`DummyGlobalForecaster` is a lightweight baseline that computes summary statistics\n",
    "during pretraining. It requires no deep learning dependencies and is useful for\n",
    "testing the pretraining API and as a comparison baseline.\n",
    "\n",
    "The three-step workflow is always the same, regardless of the forecaster:\n",
    "\n",
    "1. **`pretrain(y_panel)`** on panel data\n",
    "2. **`fit(y_target)`** on the target series\n",
    "3. **`predict(fh)`** to get forecasts\n",
    "\n",
    "### Step 1: Pretrain\n",
    "\n",
    "The forecaster learns global statistics (mean, std) from all 4 product series.\n",
    "After this call, the `state` property changes from `\"new\"` to `\"pretrained\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lr3df87w8hg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State:        pretrained\n",
      "Global mean:  146.12\n",
      "Instances:    4\n"
     ]
    }
   ],
   "source": [
    "forecaster = DummyGlobalForecaster(strategy=\"mean\")\n",
    "\n",
    "forecaster.pretrain(y_panel)\n",
    "\n",
    "print(f\"State:        {forecaster.state}\")\n",
    "print(f\"Global mean:  {forecaster.global_mean_:.2f}\")\n",
    "print(f\"Instances:    {forecaster.n_pretrain_instances_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bmsteocjs3",
   "metadata": {},
   "source": [
    "### Step 2: Fit on the target series\n",
    "\n",
    "Because the forecaster is in the `\"pretrained\"` state, `fit` preserves the\n",
    "pretrained statistics and only sets the context (cutoff, last value) for the\n",
    "target series. The state moves to `\"fitted\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82bmmcgsd3v",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: fitted\n"
     ]
    }
   ],
   "source": [
    "forecaster.fit(y_target, fh=[1, 2, 3])\n",
    "print(f\"State: {forecaster.state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j6ip3vwc3h",
   "metadata": {},
   "source": [
    "### Step 3: Predict\n",
    "\n",
    "With the `\"mean\"` strategy, the forecaster simply repeats the global mean learned\n",
    "during pretraining for each forecast horizon step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "enx651wx1qk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2005-01    146.120833\n",
       "2005-02    146.120833\n",
       "2005-03    146.120833\n",
       "Freq: M, Name: Sales, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = forecaster.predict()\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edxa0tfxhs5",
   "source": "The plot shows the target series history and the 3-step-ahead forecast. The\n`\"mean\"` strategy produces a flat forecast at the global mean learned during\npretraining (dashed line).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "qz0k7297uk8",
   "source": "fig, ax = plt.subplots(figsize=(10, 4))\n\nax.plot(y_target.index.to_timestamp(), y_target.values, label=\"History\")\nax.plot(\n    y_pred.index.to_timestamp(), y_pred.values,\n    \"o--\", color=\"C1\", label=\"Forecast (pretrained mean)\",\n)\nax.axhline(\n    forecaster.global_mean_, color=\"C1\", linestyle=\":\", alpha=0.5,\n    label=f\"Global mean ({forecaster.global_mean_:.1f})\",\n)\nax.set_title(\"DummyGlobalForecaster: Pretrain + Fit + Predict\")\nax.set_xlabel(\"Date\")\nax.set_ylabel(\"Sales\")\nax.legend()\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b4l37q7yaak",
   "metadata": {},
   "source": [
    "### Inspecting pretrained vs. fitted parameters\n",
    "\n",
    "Attributes set during `pretrain` and `fit` are tracked separately. This\n",
    "separation matters because pretrained attributes survive cloning (see below)\n",
    "while fitted attributes do not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0s47wl2qlswo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained parameters (set by pretrain):\n",
      "  global_mean_: 146.12083333333334\n",
      "  global_std_: 44.961070931479775\n",
      "  n_pretrain_instances_: 4\n",
      "  n_pretrain_timepoints_: 240\n",
      "\n",
      "Fitted parameters (set by fit):\n",
      "  global_mean: 146.12083333333334\n",
      "  global_std: 44.961070931479775\n",
      "  last_value: 119.0\n",
      "  n_pretrain_instances: 4\n",
      "  n_pretrain_timepoints: 240\n"
     ]
    }
   ],
   "source": [
    "print(\"Pretrained parameters (set by pretrain):\")\n",
    "for key, val in sorted(forecaster.get_pretrained_params().items()):\n",
    "    print(f\"  {key}: {val}\")\n",
    "\n",
    "print(\"\\nFitted parameters (set by fit):\")\n",
    "for key, val in sorted(forecaster.get_fitted_params().items()):\n",
    "    print(f\"  {key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cb9jzw6gqb",
   "metadata": {},
   "source": [
    "## Example 2: LTSFLinearForecaster (deep learning)\n",
    "\n",
    "For neural network forecasters, pretraining trains the network weights on panel\n",
    "data. The subsequent `fit` call fine-tunes those same weights on the target series\n",
    "instead of starting from random initialization.\n",
    "\n",
    "This section requires `torch`. If it is not installed, skip to the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zxbyp4kmxr",
   "metadata": {},
   "outputs": [],
   "source": "from sktime.forecasting.ltsf import LTSFLinearForecaster\n\nnn_forecaster = LTSFLinearForecaster(\n    seq_len=24,\n    pred_len=6,\n    num_epochs=3,\n    batch_size=16,\n    lr=1e-3,\n)\n\nnn_forecaster.pretrain(y_panel)\nprint(f\"State:     {nn_forecaster.state}\")\nprint(f\"Instances: {nn_forecaster.n_pretrain_instances_}\")\n\n# hold out last pred_len observations for evaluation later\ny_train = y_target.iloc[:-nn_forecaster.pred_len]\ny_test = y_target.iloc[-nn_forecaster.pred_len:]"
  },
  {
   "cell_type": "markdown",
   "id": "85j6geld62v",
   "metadata": {},
   "source": [
    "Fine-tune the pretrained network on the target series and produce forecasts.\n",
    "The forecasting horizon must not exceed `pred_len` (the network's output\n",
    "dimension, fixed at construction time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mpm86lngx2m",
   "metadata": {},
   "outputs": [],
   "source": "fh = ForecastingHorizon(list(range(1, nn_forecaster.pred_len + 1)), is_relative=True)\n\nnn_forecaster.fit(y_train, fh=fh)\ny_pred_nn = nn_forecaster.predict()\n\nprint(f\"State: {nn_forecaster.state}\")\ny_pred_nn"
  },
  {
   "cell_type": "markdown",
   "id": "fy5owrqnnxc",
   "source": "### Pretrained vs. fit-only comparison\n\nTo see the effect of pretraining, we hold out the last 6 observations of the\ntarget series as ground truth. We then train two `LTSFLinearForecaster` models\nwith the same hyperparameters: one pretrained on the panel, one fit from scratch.\nThe plot compares both forecasts against the held-out actuals.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "0dmxcjnfekl7",
   "source": "# fit-only baseline (no pretraining)\nnn_baseline = LTSFLinearForecaster(\n    seq_len=24, pred_len=6, num_epochs=3, batch_size=16, lr=1e-3,\n)\nnn_baseline.fit(y_train, fh=fh)\ny_pred_baseline = nn_baseline.predict()\n\nfig, ax = plt.subplots(figsize=(10, 4))\n\n# show only the last 24 months of training data for readability\ny_recent = y_train.iloc[-24:]\nax.plot(y_recent.index.to_timestamp(), y_recent.values, color=\"C0\", label=\"History\")\n\n# connect forecast lines to the last history point\nlast_train_idx = y_train.index[-1:]\nlast_train_val = y_train.iloc[-1]\n\ny_truth_plot = pd.Series(\n    [last_train_val] + y_test.values.tolist(),\n    index=last_train_idx.append(y_test.index),\n)\ny_pretrain_plot = pd.Series(\n    [last_train_val] + y_pred_nn.values.tolist(),\n    index=last_train_idx.append(y_pred_nn.index),\n)\ny_baseline_plot = pd.Series(\n    [last_train_val] + y_pred_baseline.values.tolist(),\n    index=last_train_idx.append(y_pred_baseline.index),\n)\n\nax.plot(\n    y_truth_plot.index.to_timestamp(), y_truth_plot.values,\n    \"o-\", color=\"C0\", alpha=0.4, label=\"Ground truth\",\n)\nax.plot(\n    y_pretrain_plot.index.to_timestamp(), y_pretrain_plot.values,\n    \"s--\", color=\"C1\", label=\"Pretrained + fit\",\n)\nax.plot(\n    y_baseline_plot.index.to_timestamp(), y_baseline_plot.values,\n    \"^--\", color=\"C2\", label=\"Fit only (no pretraining)\",\n)\nax.set_title(\"LTSFLinearForecaster: Pretrained vs. Fit-Only\")\nax.set_xlabel(\"Date\")\nax.set_ylabel(\"Sales\")\nax.legend()\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "wihoe0rzrh",
   "metadata": {},
   "source": [
    "## Incremental pretraining\n",
    "\n",
    "In practice, panel data may arrive in batches. Calling `pretrain` a second time\n",
    "on an already pretrained forecaster invokes `_pretrain_update` internally,\n",
    "allowing the implementation to decide how to incorporate new data.\n",
    "\n",
    "How the update works depends on the forecaster:\n",
    "- **`DummyGlobalForecaster`** recomputes statistics from the new batch only (replacing, not accumulating).\n",
    "- **Neural network forecasters** (e.g., `LTSFLinearForecaster`) continue training from the current weights, achieving true incremental learning.\n",
    "\n",
    "This works from both the `\"pretrained\"` and `\"fitted\"` states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "tyq3yyxtpjj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After batch 1: mean=3.5480, instances=3\n",
      "After batch 2: mean=2.7544, instances=2\n"
     ]
    }
   ],
   "source": [
    "incremental = DummyGlobalForecaster(strategy=\"mean\")\n",
    "\n",
    "batch_1 = _make_hierarchical(\n",
    "    hierarchy_levels=(3,), min_timepoints=24, max_timepoints=24, random_state=0,\n",
    ")\n",
    "incremental.pretrain(batch_1)\n",
    "print(f\"After batch 1: mean={incremental.global_mean_:.4f}, \"\n",
    "      f\"instances={incremental.n_pretrain_instances_}\")\n",
    "\n",
    "batch_2 = _make_hierarchical(\n",
    "    hierarchy_levels=(2,), min_timepoints=24, max_timepoints=24, random_state=42,\n",
    ")\n",
    "incremental.pretrain(batch_2)\n",
    "print(f\"After batch 2: mean={incremental.global_mean_:.4f}, \"\n",
    "      f\"instances={incremental.n_pretrain_instances_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l6akybli84",
   "metadata": {},
   "source": [
    "## Cloning preserves pretrained state\n",
    "\n",
    "sktime's `.clone()` method copies pretrained attributes to the clone. This is\n",
    "critical for cross-validation and hyperparameter tuning, where estimators are\n",
    "cloned internally so that each fold starts from the same pretrained baseline.\n",
    "\n",
    "**Important:** `sklearn.base.clone` does **not** preserve pretrained state.\n",
    "sktime's CV and tuning tools use `.clone()` internally, so this works\n",
    "transparently when using `ForecastingGridSearchCV` and similar utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2876qa1pu9h",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: state=pretrained, mean=146.12\n",
      "Clone:    state=pretrained, mean=146.12\n"
     ]
    }
   ],
   "source": [
    "original = DummyGlobalForecaster()\n",
    "original.pretrain(y_panel)\n",
    "\n",
    "cloned = original.clone()\n",
    "\n",
    "print(f\"Original: state={original.state}, mean={original.global_mean_:.2f}\")\n",
    "print(f\"Clone:    state={cloned.state}, mean={cloned.global_mean_:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kd2z47p6ktr",
   "metadata": {},
   "source": [
    "## Discovering pretrainable forecasters\n",
    "\n",
    "Not every forecaster supports pretraining. Those that do declare the\n",
    "`capability:pretrain` tag. Use `all_estimators` to list them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9danamejd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DummyGlobalForecaster</td>\n",
       "      <td>&lt;class 'sktime.forecasting.dummy_global.DummyG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LTSFLinearForecaster</td>\n",
       "      <td>&lt;class 'sktime.forecasting.ltsf.LTSFLinearFore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LTSFNLinearForecaster</td>\n",
       "      <td>&lt;class 'sktime.forecasting.ltsf.LTSFNLinearFor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                                             object\n",
       "0  DummyGlobalForecaster  <class 'sktime.forecasting.dummy_global.DummyG...\n",
       "1   LTSFLinearForecaster  <class 'sktime.forecasting.ltsf.LTSFLinearFore...\n",
       "2  LTSFNLinearForecaster  <class 'sktime.forecasting.ltsf.LTSFNLinearFor..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_estimators(\n",
    "    \"forecaster\",\n",
    "    filter_tags={\"capability:pretrain\": True},\n",
    "    as_dataframe=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gkqg3px5vk",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key takeaways from this notebook:\n",
    "\n",
    "- **`pretrain(y_panel)`** learns shared patterns from panel data and sets state to `\"pretrained\"`\n",
    "- **`fit(y_series)`** fine-tunes on a single series, preserving pretrained weights\n",
    "- **`get_pretrained_params()`** and **`get_fitted_params()`** inspect parameters from each phase separately\n",
    "- Calling `pretrain` again invokes **`_pretrain_update`**, whose behavior is implementation-specific\n",
    "- sktime's **`.clone()`** preserves pretrained state, enabling cross-validation on pretrained models\n",
    "- Use **`all_estimators`** with `filter_tags={\"capability:pretrain\": True}` to discover pretrainable forecasters\n",
    "\n",
    "**Next steps**\n",
    "- [Hierarchical and global forecasting](../01c_forecasting_hierarchical_global.ipynb) for panel data concepts and global models\n",
    "- [Forecasting with sktime](../01_forecasting.ipynb) for the general forecasting workflow\n",
    "- The [API reference](https://www.sktime.net/en/stable/api_reference/forecasting.html) lists all forecasters with their capability tags"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}