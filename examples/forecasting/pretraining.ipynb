{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-01",
   "metadata": {},
   "source": [
    "# Pretraining forecasters on panel data\n",
    "\n",
    "Pretraining allows a forecaster to learn shared temporal patterns from a\n",
    "collection of related time series (panel data) before being fine-tuned on a\n",
    "specific target series.\n",
    "\n",
    "This is conceptually different from **foundation models** (Chronos, MOIRAI,\n",
    "TimesFM, etc.) that ship pre-trained on massive external corpora. The\n",
    "``pretrain`` API lets you train on **your own domain data**, giving you full\n",
    "control over what the model learns.\n",
    "\n",
    "## When to use pretraining\n",
    "\n",
    "| Approach | Use when |\n",
    "|---|---|\n",
    "| ``fit`` only | You have a single series with enough history |\n",
    "| ``pretrain`` + ``fit`` | You have related series and want transfer learning on your own data |\n",
    "| Foundation model | You want zero-shot or few-shot forecasting from a large pre-trained model |\n",
    "| Global forecasting | You want a single model that predicts all series jointly (no per-series fine-tuning) |\n",
    "\n",
    "## Estimator state lifecycle\n",
    "\n",
    "Forecasters in sktime have three states, accessible via the ``state`` property:\n",
    "\n",
    "```\n",
    "new ──pretrain()──> pretrained ──fit()──> fitted ──predict()──> ...\n",
    " │                                          ^\n",
    " └──────────fit()───────────────────────────┘\n",
    "```\n",
    "\n",
    "Calling ``fit`` on a ``\"new\"`` forecaster resets and trains from scratch (the\n",
    "standard workflow). Calling ``fit`` on a ``\"pretrained\"`` forecaster preserves\n",
    "the pretrained weights and fine-tunes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-02",
   "metadata": {},
   "source": [
    "## Setup: loading panel data\n",
    "\n",
    "We use the hierarchical sales toy dataset, which contains monthly sales for\n",
    "4 product groups across 2 product lines (240 rows total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_hierarchical_sales_toydata\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "\n",
    "y_panel = load_hierarchical_sales_toydata()\n",
    "\n",
    "print(f\"Shape: {y_panel.shape}\")\n",
    "print(f\"Index levels: {y_panel.index.names}\")\n",
    "print(f\"Unique series: {len(y_panel.index.droplevel(-1).unique())}\")\n",
    "y_panel.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-04",
   "metadata": {},
   "source": [
    "## Basic example with DummyGlobalForecaster\n",
    "\n",
    "``DummyGlobalForecaster`` is a lightweight baseline that computes summary\n",
    "statistics during pretraining (no deep learning dependencies required).\n",
    "It is useful for testing the API and as a comparison baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.dummy_global import DummyGlobalForecaster\n",
    "\n",
    "forecaster = DummyGlobalForecaster(strategy=\"mean\")\n",
    "\n",
    "# Step 1: pretrain on the full panel\n",
    "forecaster.pretrain(y_panel)\n",
    "print(f\"State: {forecaster.state}\")\n",
    "print(f\"Global mean learned: {forecaster.global_mean_:.2f}\")\n",
    "print(f\"Instances seen: {forecaster.n_pretrain_instances_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: fit on a single target series\n",
    "y_target = y_panel.xs((\"Food preparation\", \"Hobs\"))[\"Sales\"]\n",
    "forecaster.fit(y_target, fh=[1, 2, 3])\n",
    "print(f\"State: {forecaster.state}\")\n",
    "\n",
    "# Step 3: predict\n",
    "y_pred = forecaster.predict()\n",
    "print(f\"\\nPredictions (global mean repeated):\\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-07",
   "metadata": {},
   "source": [
    "## Inspecting pretrained parameters\n",
    "\n",
    "Attributes set during ``pretrain`` are tracked separately from those set during\n",
    "``fit``. Use ``get_pretrained_params()`` to inspect them, and\n",
    "``get_fitted_params()`` to inspect fit-time attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pretrained parameters (from pretrain):\")\n",
    "for key, val in sorted(forecaster.get_pretrained_params().items()):\n",
    "    print(f\"  {key}: {val}\")\n",
    "\n",
    "print(\"\\nFitted parameters (from fit):\")\n",
    "for key, val in sorted(forecaster.get_fitted_params().items()):\n",
    "    print(f\"  {key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-09",
   "metadata": {},
   "source": [
    "## Deep learning example with LTSFLinearForecaster\n",
    "\n",
    "For neural network based forecasters, pretraining trains the network weights\n",
    "on panel data. The subsequent ``fit`` call fine-tunes those weights on the\n",
    "target series rather than initialising from random weights.\n",
    "\n",
    "This requires ``torch`` to be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.ltsf import LTSFLinearForecaster\n",
    "\n",
    "nn_forecaster = LTSFLinearForecaster(\n",
    "    seq_len=24,\n",
    "    pred_len=6,\n",
    "    num_epochs=3,\n",
    "    batch_size=16,\n",
    "    lr=1e-3,\n",
    ")\n",
    "\n",
    "# Pretrain on the full panel\n",
    "nn_forecaster.pretrain(y_panel)\n",
    "print(f\"State: {nn_forecaster.state}\")\n",
    "print(f\"Instances seen: {nn_forecaster.n_pretrain_instances_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune on a single series and predict\n",
    "y_target = y_panel.xs((\"Food preparation\", \"Hobs\"))[\"Sales\"]\n",
    "fh = ForecastingHorizon(list(range(1, nn_forecaster.pred_len + 1)), is_relative=True)\n",
    "\n",
    "nn_forecaster.fit(y_target, fh=fh)\n",
    "y_pred = nn_forecaster.predict()\n",
    "print(f\"State: {nn_forecaster.state}\")\n",
    "print(f\"\\nPredictions:\\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Incremental pretraining\n",
    "\n",
    "Calling ``pretrain`` a second time on an already pretrained (or fitted)\n",
    "forecaster triggers ``_pretrain_update`` instead of ``_pretrain``. This enables\n",
    "incremental learning from additional data batches without rebuilding the model\n",
    "from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.utils._testing.hierarchical import _make_hierarchical\n",
    "\n",
    "incremental = DummyGlobalForecaster(strategy=\"mean\")\n",
    "\n",
    "# First batch\n",
    "batch_1 = _make_hierarchical(\n",
    "    hierarchy_levels=(3,), min_timepoints=24, max_timepoints=24, random_state=0,\n",
    ")\n",
    "incremental.pretrain(batch_1)\n",
    "print(f\"After batch 1: mean={incremental.global_mean_:.4f}, \"\n",
    "      f\"instances={incremental.n_pretrain_instances_}\")\n",
    "\n",
    "# Second batch -- pretrain is called again, triggers _pretrain_update\n",
    "batch_2 = _make_hierarchical(\n",
    "    hierarchy_levels=(2,), min_timepoints=24, max_timepoints=24, random_state=42,\n",
    ")\n",
    "incremental.pretrain(batch_2)\n",
    "print(f\"After batch 2: mean={incremental.global_mean_:.4f}, \"\n",
    "      f\"instances={incremental.n_pretrain_instances_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Cloning preserves pretrained state\n",
    "\n",
    "When a pretrained forecaster is cloned via sktime's ``.clone()`` method, the\n",
    "pretrained attributes are copied to the clone. This is important for\n",
    "cross-validation and tuning, where the estimator is cloned internally.\n",
    "\n",
    "Note: ``sklearn.base.clone`` does **not** preserve pretrained state. Always\n",
    "use the sktime ``.clone()`` method (which is what sktime's CV and tuning\n",
    "tools use internally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = DummyGlobalForecaster()\n",
    "original.pretrain(y_panel)\n",
    "print(f\"Original: state={original.state}, mean={original.global_mean_:.2f}\")\n",
    "\n",
    "cloned = original.clone()\n",
    "print(f\"Clone:    state={cloned.state}, mean={cloned.global_mean_:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Discovering pretrainable forecasters\n",
    "\n",
    "Forecasters that support pretraining declare the ``capability:pretrain`` tag.\n",
    "You can find all of them with ``all_estimators``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\n",
    "    \"forecaster\",\n",
    "    filter_tags={\"capability:pretrain\": True},\n",
    "    as_dataframe=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- ``pretrain(y_panel)`` learns from panel data and sets state to ``\"pretrained\"``\n",
    "- ``fit(y_series)`` fine-tunes on a single series, preserving pretrained weights\n",
    "- ``get_pretrained_params()`` inspects what was learned during pretraining\n",
    "- Calling ``pretrain`` again triggers incremental updates\n",
    "- sktime's ``.clone()`` preserves pretrained state (important for CV/tuning)\n",
    "- Use ``all_estimators`` with ``filter_tags={\"capability:pretrain\": True}``\n",
    "  to discover pretrainable forecasters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}