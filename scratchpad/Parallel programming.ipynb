{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import math\n",
    "import time\n",
    "import pytest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from dask import compute, delayed\n",
    "import dask.threaded\n",
    "import joblib\n",
    "\n",
    "from sklearn.utils.testing import assert_array_equal\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def read_data(file):\n",
    "    '''\n",
    "    adhoc function to read data\n",
    "    '''\n",
    "    data = file.readlines()\n",
    "    rows = [row.decode('utf-8').strip().split('  ') for row in data]\n",
    "    X = pd.DataFrame(rows, dtype=np.float)\n",
    "    y = X.pop(0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, the classification labels are used as regression targets for testing\n",
    "url = 'http://www.timeseriesclassification.com/Downloads/GunPoint.zip'\n",
    "url = urlopen(url)\n",
    "zipfile = ZipFile(BytesIO(url.read()))\n",
    "\n",
    "train_file = zipfile.open('GunPoint_TRAIN.txt')\n",
    "X_train_pd, y_train_pd = read_data(train_file)\n",
    "\n",
    "test_file = zipfile.open('GunPoint_TEST.txt')\n",
    "X_test_pd, y_test_pd = read_data(test_file)\n",
    "Xsf_test = pd.Series([row for _, row in X_test_pd.iterrows()])\n",
    "Xdf_test = pd.DataFrame({'ts': Xsf_test, 'ts_copy': Xsf_test})\n",
    "\n",
    "y_train = pd.Series(np.array(y_train_pd, dtype=np.int))\n",
    "Xsf_train = pd.Series([row for _, row in X_train_pd.iterrows()])\n",
    "Xdf_train = pd.DataFrame({'ts': Xsf_train, 'ts_copy': Xsf_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsf_loong = pd.concat([Xsf_train for _ in range(200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942 ms ± 30.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# using pandas inbuilt function\n",
    "%timeit Xsf_loong.apply(np.mean)\n",
    "# I think we cannot use pandas groupby for inbuilt parallelism\n",
    "# as mutable types (our pd.Series elements in each cell) cannot be\n",
    "# hashed, which apparently is a requirement\n",
    "target = Xsf_loong.apply(np.mean)  # for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920 ms ± 14.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# using explicit for loop\n",
    "function = lambda X: pd.DataFrame([np.mean(row) for row in X])\n",
    "%timeit function(Xsf_loong)\n",
    "# looks like pandas is currently using explicit for loop internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539 ms ± 23.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# using joblib for parallel processing after splitting the dataframe\n",
    "with joblib.Parallel(n_jobs=2) as parallel:\n",
    "    function = lambda Z: pd.concat(parallel(joblib.delayed(lambda X: X.apply(np.mean))(part) for part in np.array_split(Z, 2)))\n",
    "    %timeit function(Xsf_loong)\n",
    "# dataframe was split into two and processed in parallel\n",
    "# the speed-up can easily be seen\n",
    "got = function(Xsf_loong)  # for comparison\n",
    "assert_array_equal(got, target)  # no difference in the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769 µs ± 97.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# using Dask (a pandas replacement, with inherent parallel processing)\n",
    "# it basically splits the data frame for parallel processing\n",
    "# but is more well managed and scales to clusters\n",
    "# can also work with big huge datasets without loading everything\n",
    "# into the RAM\n",
    "Dsf_train = dd.from_pandas(Xsf_train, npartitions=3)\n",
    "# should specify output datatype of the function\n",
    "%timeit Dsf_train.apply(np.mean, meta=float)\n",
    "# This is byfar the easiest and quickest option\n",
    "# But, this is not a drop-in replacement for pandas\n",
    "# Please see dask-ml, which has a sklearn clone with dask compatibility\n",
    "# the time shown is only for graph making not actual computation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
