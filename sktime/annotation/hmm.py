# -*- coding: utf-8 -*-
"""
HMM Annotation Estimator.

Implements a basic Hidden Markov Model (HMM) as an annotation estimator.
To read more about the algorithm, check out the wikipedia page:
(https://en.wikipedia.org/wiki/Hidden_Markov_model
"""
from math import isclose
from typing import Tuple

import numpy as np

from sktime.annotation.base._base import BaseSeriesAnnotator

__author__ = ["miraep8"]
__all__ = ["HMM"]


class HMM(BaseSeriesAnnotator):
    """Implements a simple HMM fitted with viterbi algorithm.

    The HMM annotation estimator facilitates the appilcation of
    the vertibi algorithm to fit a sequence of 'hidden state' class
    annotations (represented by an array of integers the same size
    as the observation) to a sequence of observations.

    This is done by finding the most likely path given the emission
    probabilities - (ie the probability that a particular observation
    would be generated by a given hidden state), the transition prob
    (ie the probability of transitioning from one state to another or
    staying in the same state) and the initial probabilities - ie the
    belief of the probability distribution of hidden states at the
    start of the observation sequence).

    Parameters
    ----------
    emission_funcs : a list of functions, which should be properly
        normalized PDFs over the same space as the observed data.
    transition_prob_mat: a nxn array of probabilities, where 'n'
        represents the number of hidden states in the HMM.  Each
        row should sumn to 1 in order to be properly normalized
        (ie the j'th column in the i'th row represents the
        probability of transitioning from state i to state j.)
    initial_probs: optional, a 1d array of probabilities across
        the starting states. Should match prior beliefs.  If none
        is passed will give each state an equal initial probability.

    Examples
    --------
    >>> from sktime.annotation.hmm import HMM
    >>> from scipy.stats import norm
    >>> from numpy import asarray
    >>> # define the emission probs for our HMM model:
    >>> centers = [3.5,-5]
    >>> sd = [.25 for i in centers]
    >>> emi_funcs = [(norm.pdf, {'loc': mean,
    ...  'scale': sd[ind]}) for ind, mean in enumerate(centers)]
    >>> test = HMM(emi_funcs, asarray([[0.25,0.75], [0.666, 0.333]]))
    >>> # generate synthetic data (or of course use your own!)
    >>> obs = asarray([3.7,3.2,3.4,3.6,-5.1,-5.2,-4.9])
    >>> test = test.fit(obs)
    >>> labels = test.predict(obs)
    """

    # plan to update to make multivariate.
    _tags = {"univariate-only": True, "fit_is_empty": False}

    def __init__(
        self,
        emission_funcs: list,
        transition_prob_mat: np.ndarray,
        initial_probs: np.ndarray = None,
    ):
        self.initial_probs = initial_probs
        self.num_states = len(emission_funcs)
        self.emission_funcs = emission_funcs
        self.transition_prob_mat = transition_prob_mat
        self.states = [i for i in range(self.num_states)]
        self._validate_init()
        super(HMM, self).__init__(fmt="dense", labels="int_label")

    def _validate_init(self):
        """Verify that the parameters passed to init are well behaved."""
        tran_mat_len = len(self.transition_prob_mat[:, 0])
        # transition_prob_mat should be square:
        if not len(self.transition_prob_mat.shape) == 2 or not tran_mat_len == len(
            self.transition_prob_mat[0, :]
        ):
            raise ValueError(
                "Transtion Probability must be 2D square, but got an"
                f"object of size {self.transition_prob_mat.shape}"
            )
        # number of states should be consistent!
        init_prob_len = self.num_states
        if self.initial_probs is not None:
            init_prob_len = len(self.initial_probs)
        if not tran_mat_len == self.num_states == init_prob_len:
            raise ValueError(
                "Number of hidden states is inconsistent!  Was passed "
                f"{self.num_states} number of emission funcs, {tran_mat_len}"
                f" as the size of the transition matrix, and  "
                f" {init_prob_len} number of initial state probs"
            )
        for i in range(len(self.transition_prob_mat)):
            if not isclose(
                1, sum(self.transition_prob_mat[i, :]), rel_tol=5e-2, abs_tol=0.0
            ):
                raise ValueError(
                    "The sum of all rows in the transition matrix must be 1."
                )
        if self.initial_probs is not None and not sum(self.initial_probs) == 1:
            raise ValueError("Sum of initial probs should be 1.")

    @classmethod
    def _calculate_trans_mats(
        cls,
        initial_probs: np.ndarray,
        emi_probs: np.ndarray,
        transition_prob_mat: np.ndarray,
        num_obs: int,
        num_states: int,
    ) -> Tuple[np.array, np.array]:
        """Calculate the transition mats used in the viterbi algorithm.

        Parameters
        ----------
        initial_probs : (np.ndarray of float) - A nx1 dimensional array where n
            represents the number of hidden states in the model. It
            contains the probability that hidden state for the state
            before the first observation was state n.  Should sum to 1.
        emi_probs : (np.ndarray of float)- A nxm dimensional array, where n is the
            number of hidden states and m is the number of observations.
            For a given observation, it will provide the probability for
            each of the hidden states that they could have given rise to that
            observation. Each entry should be beteen 0 and 1
        transition_prob_mat : (np.ndarray) - A nxn dimensional array where n is
            the number of hidden states in the model. The jth col in the ith row
            represents the probability of transitioning to state j from state i.
            Thus each row should sum to 1.
        num_obs : (int) the number of observations (m)
        num_states : (int) the number of hidden states (n)

        Returns
        -------
        trans_prob : (np.ndarray) an nxm dimensional array which represents the
            maximum probability of the hidden state of observation m is state n.
        trans_id : (np.ndarray) a nxm dimensional array which for each observation
            "i" and state "j" the i,j entry records the state_id of the most
            likely state that could have led to the hidden state being "i" for
            observation "j".
        """
        # trans_prob represents the maximum probability of being in that
        # state at that stage
        trans_prob = np.zeros((num_states, num_obs))
        trans_prob[:, 0] = np.log(initial_probs)

        # trans_id is the index of the state that would have been the most
        # likely preceeding state.
        trans_id = np.zeros((num_states, num_obs), dtype=np.int32)

        # use Vertibi Algorithm to fill in trans_prob and trans_id:
        for i in range(1, num_obs):
            # use log probabilities to try to keep nums reasonable -Inf
            # means 0 probability
            paths = np.zeros((num_states, num_states))
            for j in range(num_states):
                paths[j, :] += trans_prob[:, i - 1]  # adds prev trans_prob column-wise
                paths[:, j] += np.log(emi_probs[:, i])  # adds log(probs_sub) row-wise
            paths += np.log(
                transition_prob_mat
            )  # adds log(transition_prob_mat) element-wise
            trans_id[:, i] = np.argmax(paths, axis=0)
            trans_prob[:, i] = np.max(paths, axis=0)

        if np.any(np.isinf(trans_prob[:, -1])):
            raise ValueError("Change parameters, the distribution doesn't work")

        return trans_prob, trans_id

    @classmethod
    def _make_emission_probs(
        cls, emission_funcs: list, observations: np.ndarray
    ) -> np.ndarray:
        """Calculate the prob each obs comes from each hidden state."""
        # assign emission probabilities from each state to each position:

        emi_probs = np.zeros(shape=(len(emission_funcs), len(observations)))
        for state_id, emission_tuple in enumerate(emission_funcs):
            emission_func = emission_tuple[0]
            kwargs = emission_tuple[1]
            emi_probs[state_id, :] = np.array(
                [emission_func(x, **kwargs) for x in observations]
            )
        return emi_probs

    def _hmm_viterbi_label(self) -> np.array:
        """Assign hidden state ids to all observations based on most likely path.

        Parameters
        ----------
        self - an HMM instance which already has already

        Returns
        -------
            -hmm_fit: a 2xn array with the first column being position and the second
                column being a peak assignment.
        """
        hmm_fit = np.zeros(self.num_obs)
        # Now we trace backwards and find the most likely path:
        max_inds = np.zeros(self.num_obs, dtype=np.int32)
        max_inds[-1] = np.argmax(self.trans_prob[:, -1])
        hmm_fit[-1] = self.states[max_inds[-1]]
        for index in reversed(list(range(1, self.num_obs))):
            max_inds[index - 1] = self.trans_id[max_inds[index], index]
            hmm_fit[index - 1] = self.states[max_inds[index - 1]]
        return hmm_fit

    def _fit(self, X, Y=None):
        """Calculate the transition matrices for the given model/observation."""
        self.num_obs = len(X)
        emi_probs = HMM._make_emission_probs(self.emission_funcs, X)
        init_probs = self.initial_probs
        # if no initial_probs were supplied assign all states equal prob:
        if self.initial_probs is None:
            init_probs = 1.0 / (self.num_states) * np.ones(self.num_states)
        trans_prob, trans_id = HMM._calculate_trans_mats(
            init_probs,
            emi_probs,
            self.transition_prob_mat,
            self.num_obs,
            self.num_states,
        )
        self.trans_prob = trans_prob
        self.trans_id = trans_id
        return self

    def _predict(self, X):
        """Use the transition matrices to calculate the most likely state."""
        return self._hmm_viterbi_label()

    @classmethod
    def get_test_params(cls, parameter_set="default"):
        """Return testing parameter settings for the estimator.

        Parameters
        ----------
        parameter_set : str, default="default"
            Name of the set of test parameters to return, for use in tests. If no
            special parameters are defined for a value, will return `"default"` set.

        Returns
        -------
        params : dict or list of dict
        """
        from numpy import asarray
        from scipy.stats import norm

        # define the emission probs for our HMM model:
        centers = [3.5, -5]
        sd = [0.25 for i in centers]
        emi_funcs = [
            (norm.pdf, {"loc": mean, "scale": sd[ind]})
            for ind, mean in enumerate(centers)
        ]
        # make the transition_mat:
        trans_mat = asarray([[0.25, 0.75], [0.666, 0.333]])
        params_1 = {"emission_funcs": emi_funcs, "transition_prob_mat": trans_mat}
        # also try with passing initial_probs:
        params_2 = {
            "emission_funcs": emi_funcs,
            "transition_prob_mat": trans_mat,
            "initial_probs": asarray([0.2, 0.8]),
        }
        return [params_1, params_2]
